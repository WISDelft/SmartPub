The results show our advanced Skipgram model is promising and superior. SIGIR 
THE PROPOSED APPROACH
Here we introduce the proposed approach    , including the basic Skip-gram model and the advanced Skip-gram model. Each word type is associated with its own embedding. Intuitively    , affirmative negated words are mapped to the affirmative negated representations    , which can be used to predict the surrounding words and word sentiment in affirmative negated context. We propose an advanced Skip-gram model which incorporates word sentiment and negation into the basic Skip-gram model. For each input tweet s    , we build a sentence matrix S ∈ R d×|s|     , where each column i represents a word embedding wi at the corresponding position i in a sentence see 
Convolutional feature maps
 The aim of the convolutional layer is to extract patterns    , i.e. Here we propose to learn the affirmative and negated word embedding simultaneously . The elements are encoded using only two word types: the tokens spanning the phrase to be predicted are encoded with 1s and all the others with 0s. Further more    , our proposal achieves better performance efficiently and can learn much higher dimensional word embedding informatively on the large-scale data. Request permissions from permissions@acm.org. The objective of SG++ is to further incorporate negation. Hence    , we are motivated to establish a novel approach    , not only focusing on learning sentiment-specific word embedding efficiently    , but also capturing the negation information. First    , the basic Skip-gram model is extended by inserting a softmax layer    , in order to add the word sentiment polarity. , |V |.