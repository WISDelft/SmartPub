Here  , L is the log-likelihood of the implicit topic model as maximized by pLSA. TL-PLSA seems particularly effective for multiclass text classification tasks with a large number of classes more than 100 and few documents per class. Thus  , in all of the experiments  , our approaches include R-LTR- NTN plsa   , R-LTR-NTN doc2vec   , PAMM-NTNα-NDCG plsa   , and PAMM-NTNα-NDCG doc2vec . Our approach outperforms both the simple PLSA and Dual-PLSA methods  , as well as a transfer learning approach Collaborative Dual-PLSA. It shows PLSA can capture users' interest and recommend questions effectively. 4 propose a probability model called Sentiment PLSA S-PLSA for short based on the assumption that sentiment consists of multiple hidden aspects. K plsa +U + T corresponds to the results obtained when the test set was also used to learn the pLSA model  , thereby tailoring the classifiers to the task of interest transductive learning. Our immediate next target is to extend TL-PLSA with a method for estimating the number of shared classes of the two domains. Given this observation  , we are interested in the question: is regularized pLSA likely to outperform non-regularized pLSA no matter the value of K we select ? Also  , in PLSA it is assumed that all attributes motifs belonging to a component might not appear in the same observation upstream region. For example  , the R-LTR-NTN that using PLSA as document representations is denoted as R-LTR-NTN plsa . In this paper  , we utilize PLSA for discovering and matching web services. Comparing to the distributions computed with PLSA  , we see that with Net- PLSA  , we can get much smoother distributions. Unstructured PLSA and Structured PLSA  , are good at picking up a small number of the most significant aspects when K is small. As the number of clusters increases  , the performance of three methods converge to a similar level  , around 0.8. However  , PLSA found most surprising components: components containing motifs that have strong dependencies. PLSA did a poor job with the smaller yeast data  , whereas PLSA results with human data are quite interesting. The best ranking loss averaged among the four DSRs is 0.2287 given by Structured PLSA + Local Prediction compared with the baseline of 0.2865. This means that NetPLSA indeed extracts more coherence topical communities than PLSA. The most representative terms generated by CTM and PLSA are shown in Table 1. The motivation for this work was to use transfer learning  , when the source and target domain share only a subset of classes. We perform experiments on a publicly available multilingual multi-view text categorization corpus extracted from the Reuters RCV1/RCV2 corpus 1 . K plsa +U corresponds to the results obtained when an additional 10 ,000 unlabeled abstracts from the MGD database were used to learn the pLSA model semi-supervised learning. The above question can be reformulated as follows. The topic pattern First we find robust topics for each view using the PLSA approach. 2 presented an incremental automatic question recommendation framework based on PLSA. These motifs co-occur together very often. Compared to pLSA  , Lap- PLSA shows more robust performance: diversification with pLSA can underperform the baseline given an improperly set K  , while diversification with LapPLSA regularized by the subtopics from an external resource in general outperforms the baseline irrespective of the choice of K. The only exception is the case where K = 2  , which is presumably not a sensible choice for K. Second  , judging from Figure 3   , the effectiveness of each resource differs on different topic sets. Using the training blog entries  , we train an S-PLSA model. All the scores are significantly greater compared to the baseline NoDiv in Table 4. It separately extracts subtopics from ODP as described in Section 2.1 and from documents using PLSA 6. In the startup phase  , initial estimates of the hyperparameters φ 0 are obtained. Evaluation is performed via anecdotal results. We compare the topical communities identified by PLSA and NetPLSA. First we find robust topics for each view using the PLSA approach. Based on PLSA  , one can define the following joint model for predicting terms in different objects: 1. With PLSA  , although we can still see that lots of vertices in the same community are located closely  , there aren't clear boundaries between communities. Boldface indicates that the W value of a combined resource is equal or above the lowest W of the single resources that are combined. However  , our main interest here is less in accurately modeling term occurrences in documents   , and more in the potential of pLSA for automatically identifying factors that may correspond to relevant concepts or topics. This indicates that the OTM model  , which combines the statistical foundation of PLSA and the orthogonalized constraint  , improves topic representation of documents to a certain degree. Please note in all of the experiments  , PAMM-NTN was configured to direct optimize the evaluation measure of α-NDCG@20. The parameters of the final PLSA model are first initialized using the documents that have been pre-assigned to the selected cluster signatures. Combining all three resources seems to be a relatively safe choice: it improves significantly over the pLSA run on two out of the three topic sets  , and on the third topic set  , although the difference is not statistically significant with a Table 5 : Comparing LapPLSA and pLSA. That is  , with a random setting of K  , LapPLSA regularized with external resources tends to outperform non-regularized pLSA. Formally  , the PLSA model assumes that all P~ can be represented in the following functional form 6  , where it is closely related to other recent approaches for retrieval based on document-specific language models 8  , 1. From the results we can see that  , on all of the three datasets and in terms of the five diversity evaluation metrics   , our approaches R-LTR-NTN plsa   , R-LTR-NTN doc2vec   , PAMM-NTNα-NDCG plsa   , and PAMM-NTNα-NDCG doc2vec  can outperform all of the baselines. We conducted significant testing t-test on the improvements of our approaches over the baselines. In order to effectively analyze characteristics of different roles and make use of both of user roles to improve the performance of question recommendation  , we propose a Dual Role Model DRM based on PLSA to model the user in CQA precisely. Table 2 summarizes results obtained by conc-PLSA  , Fusion- LM and voted-PLSA averaged over five languages and 10  ferent initializations. The OTM model is able to take advantage of statistical foundation of PLSA without losing orthogonal property of LSA. Therefore  , instead of taking a vanilla " bag of words " approach and considering all the words modulo stop words present in the blogs  , we focus primarily on the words that are sentiment-related. The precision estimates are taken from the TREC 2009/10 diversity task data for Lemur  , and from the MovieLens 2 dataset for pLSA more details in section 4.2. Sample 1 is the result of diversification using pLSA for varying K  , and sample 2 is the result of diversification using LapPLSA Table 6: Comparing performance of LapPLSA and pLSA over random K's. For direct comparison  , Table 1provides the results of the methods of Stoica and Hearst 4 re-implementation by the authors and Seki et al. This has several key advantages: first  , it ensures that PLSA is applicable to any language  , as long as the language can be tokenized. What differentiates S-PLSA from conventional PLSA is its use of a set of appraisal words 4 as the basis for feature representation. The performance of TL-PLSA is higher when the percentage of shared classes of source and target domain is smaller. They develop a model called ARSA which stands for Auto-Regressive Sentiment-Aware to quantitatively measure the relationship between sentiment aspects and reviews . In the S-PLSA model 4  , a review can be considered as being generated under the influence of a number of hidden sentiment factors . Aside from the S-PLSA model which extracts the sentiments from blogs for predicting future product sales  , we also consider the past sale performance of the same product as another important factor in predicting the product's future sales performance. In the investigation  , we also examine the hyperparameter settings for PLSA such as initial conditional probabilities and zero estimate smoothing in the context of our problem. The hidden aspect factors in PLSA models are statistically identified from data while the aspects of Genomics Track topics are assigned by the judges but not results of statistical analyses.  The ranking loss performance of our methods Unstructured PLSA/Structured PLSA + Local Prediction/Global Prediction is almost always better than the baseline. Notice that when no explicit subtopics can be found for a query  , the regularized pLSA is reduced to the normal pLSA. The rationale is that those appraisal words  , such as " good" or " terrible"  , are more indicative of the review's sentiments than other words. In such a case  , the objective function degenerates to the log-likelihood function of PLSA with no regularization. The first column shows the automatically discovered and clustered aspects using Structured PLSA. Their Topic-Sentiment Model TSM is essentially equivalent to the PLSA aspect model with two additional topics. In conclusion  , our study opens a promising direction to question recommendation. Experiments are repeated 10 times on the whole dataset  , using different random initializations of the PLSA models. We can have the following joint model for citations based on documents in different types: We developed our model based on PLSA 4. As probability matrices are obviously non-negative  , PLSA corresponds to factorizing the joint probability matrix in non-negative factors. First  , PLSA is a probabilistic model which offers the convenience of the highly consistent probabilistic framework. From Table 1  , we see that PLSA extracts reasonable topics . However  , in terms of representing research communities  , all four topics have their limitations. The improvement over the supervised methods is shown in Figure 4. Probabilistic LSA PLSA 15 applies a probabilistic aspect model to the co-occurrence data. 1 The pattern based subtopic modeling methods are more effective than the existing topic modeling based method  , i.e. Conversely  , given the NMF formulation in eq. We can show that the new hyperparameters are given by A major benefit of S-PLSA + lies in its ability to continuously update the hyperparameters. We could have directly applied the basic PLSA to extract topics from C O . We adopt the PLSA model to tackle this novel problem. In Section 3  , topic-bridged PLSA is proposed for cross-domain text classification. 5 to regularize the implicit topic model. All runs are compared to the baseline NoDiv. Regularization with most resources or their combinations does not lead to significant improvement over the pLSA run. It then integrates these subtopics as described in Section 2.3. 8 proposed a framework to combine clusters of external resources to regularize implicit subtopics based on pLSA using random walks.   , Dn} the set of reviews obtained up to epoch n. QB S-PLSA estimates at epoch n are determined by maximizing the posterior probability using χ n : . below  , the PLSA parameters may be interpreted as probabilities. We observe that our PLSA model outperforms the cosine similarity measure in all the three data sets. This also shows that our model could alleviate the overfitting problem of PLSA. aspects. The system uses PLSA to extract K subtopic candidates from the unstructured data 7. Then PLSA is used directly to get the topic information of the user. A typical approach is the user-word aspect model applied by Qu et al. S-PLSA can be considered as the following generative model. Laplacian pLSA employs a generalized version of EM to maximize the regularized log-likelihood of the topic model  , L: 5 to regularize the implicit topic model. |1 ∼ 0.21 to around 10 by = 200. pLSA displays a higher relevance probability due to the nature of the recommendation task on this dataset. The evaluation results are shown in Section 4. We also propose a novel evaluation metric to measure the performance . The results show PLSA model can improve the quality of recommending. Evaluation is carried out by showing anecdotal results. Web queries are often short and ambiguous. First  , we see that both pLSA and LapPLSA with different resources  can outperform the baseline. As we have specified in section 3  , these methods model the user either indirectly or directly. PLSA is a latent variable model that has a probabilistic point of view. This is why we call this model semi-supervised PLSA. The results also indicate that the improvements of PAMM-NTNα-NDCG plsa and PAMM- NTNα-NDCG doc2vec over all of the baselines are significant   , in terms of all of the performance measures. Can we quantitatively prove that NetPLSA extracts better communities than PLSA ? Compared with these alternative approaches  , PLSA with conjugate prior provides a more principled and unified way to tackle all the challenges. Intuitively  , the words in our text collection CO can be classified into two categories 1 background words that are of relatively high frequency in the whole collection. In this paper  , we propose a fully automated PLSA-based Web image selection method for the Web image-gathering Our work can be regarded as the Web image version of that work. We empirically choose the number of latent variables k = 100. Documents are then assigned to each topic using the maximum posterior probability. We then select the subtopic terms from the PLSA subtopic  , which are most semantically similar to the connected subtopic candidates of ontology. Finally  , note that γ = 0 makes LapPLSA equivalent to pLSA without regularization. Second  , using clickthrough data for model training by extending PLSA to BLTM  , leads to a significant improvement Rows 4 and 5 vs. In Section 3  , we discuss the characteristics of online discussions and specifically  , blogs  , which motivate the proposal of S-PLSA in Section 4. For each blog entry b  , the sentiments towards a movie are summarized using a vector of the posterior probabilities of the hidden sentiment factors  , P z|b. We now study how the choice of these parameter values affects the prediction accuracy. The resulting semantic kernels are combined with a standard vector space representation using a heuristic weighting scheme. The other 90% were used to learn the pLSA model while the held-out set was used to prevent overfitting  , namely using the strategy of early stopping. In this paper  , we aim at an extension of the PLSA model to include the additional hyperlink structure between documents . There are many longer and less frequent motifs in the components  , which makes components like 5 and 9 quite surprising. PLSA found components with rare and long motifs. In addition to methods discussed in this paper — frequent sets  , ICA  , NMF and PLSA — there are others suitable for binary observations . Or better still  , to discover both frequent and surprising components  , use all of the methods. It assumes that each word is either drawn from a universal background topic or from a location and time dependent language model. Thus  , simply using PLSA cannot ensure the obtained topic is well-aligned to the specific domains. Thus NetPLSA ignores the various participation information for each user. They are matched to one of these C groups by applying a PLSA model on the concatenated document features. The only exception is the combination of the click logs and the Web ngrams. The picture is a little worse for average attacks. The hidden aspects caught are used to improve the performance of a ranked list by re-ranking. This indicates PLSA models are very promising in finding diverse aspects in retrieved passages. On both text sets  , OTM outperforms LSA  , PLSA  , LapPLSA in terms of classification accuracies due to the orthogonality of the topics. For text categorization  , 90% of the data were randomly selected as the training set while the other 10% were used for testing. In summary  , the ARSA model mainly comprises two components . They assume that an aligned query and document pair share the document-topic distribution. In order to visualize the hidden topics and compare different approaches  , we extract topics from the data using both PLSA and CTM. It reflects the sentiment " mass" that can be attributed to factor zj. where αi and α k are Lagrange multipliers of the constraints with respect to pnvj |z k   , we need to consider the original PLSA likelihood function and the user guidance term. In order to generate gold standard for representative phrases  , we utilize both the true DSR ratings and human annotation. Note that the PLSA model allows multiple topics per user  , reflecting the fact that each user has lots of interest. Table 3 shows that the PLSAbased techniques substantially outperform the Marginal and Query baselines  , and the full PLSA model outperforms its simpler versions. A failure here results in the exploitation of visual features which are used as input to a support-vector machine based classifier. They show that  , by including the click-through data  , their model achieves better performance compared to the PLSA. Moreover  , the improvement of CTM over PLSA and NetClus is more significant on the results of papers than other two objects. Thus the E-step remains the same. However  , the extracted topics in this way would generally not be well-aligned to the expert review. Each modifier could be represented by a set of head terms that it modifies: Similar to Unstructured PLSA  , we define k unigram language models of head terms: Θ = {θ 1   , θ 2   , ..  , θ k } as k theme models.  The ranking loss performance also varies a lot across different DSRs. In addition  , we plan to apply the EM method and PLSA model to promoting diversity on Genomics research. In order to visualize the factor solution found by PLSA we present an elucidating example. In Section 5  , we propose ARSA  , the sentiment-aware model for predicting future product sales. Second  , in most cases  , the W value of those combined resources are in between occasionally above the resources that are combined. As an illustrative example  , Figure 1shows the average relevance distribution estimate resulting for the Lemur Indri search system and the pLSA recommender –which we use as baselines in our experiments in section 4. For Lemur  , the distribution decreases from The precision estimates are taken from the TREC 2009/10 diversity task data for Lemur  , and from the MovieLens 2 dataset for pLSA more details in section 4.2. In our case  , the nodes of the graph are documents and the edge weights are defined as the closeness in location between two documents. Intuitively  , user communities grouped by basic PLSA model can represent interest topics towards item categories. However   , these extracted topics are latent variables without explicit meaning and cannot be regarded as the given categories . On the other hand  , it assigns surprisingly low probability of " windy " to Texas. It is shown to improve the quality of the extracted aspects when compared with two strong baselines. Experimental results show the PLSA model works effectively for recommending questions. The only difference is that Baseline is under PLSA formalism and our model is in SAGE formalism. 2 The semantic similarity-based weighting Sim is the best weighting strategy. Iterative Residual Rescaling IRR 1  is proposed to counteract LSA's tendency to ignore the minor-class documents . In order to understand the data analyzed  , we briefly describe the framework used to implement the lightweight comment summarizer. Intuitively  , CTM selects more related terms for each topic than PLSA  , which shows the better performance of CTM. In many cases  , however  , the reviews are continuously becoming available  , with the sentiment factors constantly changing. Table 2 shows results on further metrics  , showing also the diversification of the popularity-based recommender baseline  , in addition to pLSA. The concept features can be derived from different pLSA models with different concept granularities and used together. Intuitively  , ωt ,j represents the average fraction of the sentiment " mass " that can be attributed to the hidden sentiment factor j. where pz = j|bb ∈ Bt are obtained based a trained S- PLSA model. Instead of decomposing X into A and S  , PLSA gives the probabilities of motifs in latent components. For each component z we pick the motifs w whose probability P w|z is significantly larger than zero. It is noticeable that on topic set 1-50  , click logs remarkably outperform the other two resources across all settings of K. A possible explanation is that this topic set is derived from query logs of commercial search engines 12  , and therefore the click logs have a relatively high coverage and turn out to be an effective resource for these topics. Our probabilistic semantic approach is based on the PLSA model that is called aspect model 2. PLSA was originally used in text context for information retrieval and now has been used in web data mining 5.  represents the probability of head term w h associated with modifier wm assigned to the jth aspect. Since we are working on short comments  , there are usually only a few phrases in each comment  , so the co-occurrence of head terms in comments is not very informative. Unsupervised topic modeling has been an area of active research since the PLSA method was proposed in 17 as a probabilistic variant of the LSA method 9  , the approach widely used in information retrieval to perform dimensionality reduction of documents. Using our TPLSA model  , the common knowledge between two domains can be extracted as a prior knowledge in the model  , and then can be transferred to the test domain through the bridge with respect to common latent topics. Now that we have described our approach to model the relations between subtopics extracted from multiple resources  , the next question is: how can we combine the relations between the explicit subtopics with the implicit subtopics ? By maximizing the regularized log-likelihood  , Laplacian pLSA softly assigns documents to the same cluster if they 1 share many terms and 2 belong to the same explicit subtopics. Baseline " refers to the run without diversification. In terms of RQ4  , we find that LapPLSA regularized with explicit subtopics tends to outperform the non-regularized pLSA for cases where we do not optimize the setting of K  , and simply choose it at random from a reasonable range. In S-PLSA  , appraisal words are exploited to compose the feature vectors for blogs  , which are then used to infer the hidden sentiment factors. That implies that representing the sentiments with higher dimensional probability vectors allows S-PLSA to more fully capture the sentiment information   , which leads to more accurate prediction. It is worth noting that although we have only used S- PLSA for the purpose of prediction in this work  , it is indeed a model general enough to be applied to other scenarios. In addition  , the factor representation obtained by PLSA allows to deal with polysemous words and to explicitly distinguish between diierent meanings and diierent t ypes of word usage. We h a ve presented a novel method for automated indexing based on a statistical latent class model. Recent w ork has also shown that the beneets of PLSA extend beyond document indexing and that a similar approach can be utilized  , e.g. Also shown are simulationsize inputs for three benchmarks for comparison  , with scores from simulator-based profiling shown in parentheses. We evaluate the performance of OTM on the tasks of document classification using the method similar to 9 . Rather than applying each separately  , it is reasonable to merge them into a joint probabilistic model with a common set of underlying topics as shown in Fig. We introduce the latent variable to indicate each topic under users and questions. The amount of components looked for with ICA  , NMF and PLSA methods was 200  , and the frequency threshold percentage for finding about 200 frequent sets was 10%. Components with only one motif were left out  , as they do not include information about the relationships of the motifs . Finally  , the Quality of Services QoS is combined with the proposed semantic method to produce a final score that reflects how semantically close the query is to available services. In the first step  , we propose a topic modeling method  , called Structured PLSA  , modeling the dependency structure of phrases in short comments. Compared with Unstructured PLSA  , this method models the co-occurrence of head terms at the level of the modifiers they use instead of at the level of comments they occur. 11 One of these topics has a prior towards positive sentiment words and the other towards negative sentiment words  , where both priors are induced from sentiment labeled data. In our work  , We employ PLSA 3 to analyze a user's interest by investigating his previously asked questions and accordingly generate fine-grained question recommendation . We keep the same values for λ as were selected in the previous experiments  , and the pLSA baseline in the recommendation task. As documents belonging to each of these groups received by definition similar votes from the view-specific PLSA models  , the voting pattern representing each of these groups is called the cluster signature. We keep the C largest groups with the most documents as initial clusters. Further  , we also see in Figure 3and Figure 4that across different settings of K  , in most cases the averaged performance of LapPLSA exceeds that of pLSA. The overall approach can be decomposed into three stages: In the unsupervised learning stage  , we use pLSA to derive domain-specific cepts and to create semantic document representations over these concepts. We summarized the previous PLSA based methods for question recommendation and discovered that they can be divided into two main categories: 1 methods that model the user indirectly. Although ATM obtains comparable performance to CTM in terms of papers  , our CTM approach can obtain significant improvements in terms of authors. We have shown that the observations can be decomposed into meaningful components using the frequent sets and latent variable methods. The support of a representative opinion is defined as the size of the cluster represented by the opinion sentences. Several follow-up work tries to address the limitations of TSM from different perspectives. In addition to the user and previous queries  , the model can also include result URLs  , individual query terms or phrases  , or important relatedness indicators like the temporal delay between queries 3. According to different independence assumptions  , we implement two variants of DRM. Once a voting pattern is obtained for each multilingual document  , we attempt to group documents such that in each group  , documents share similar voting patterns. Our results have brought to light the positive impact of the first stage of our approach which can be viewed as a voting mechanism over different views.  We propose the Autoregressive Sentiment Aware ARSA model for product sales prediction  , which reflects the effects of both sentiments and past sales performance on future sales performance. Parameter q specifies the sentiment information from how many preceding days are considered  , and K indicates the number of hidden sentiment factors used by S-PLSA to represent the sentiment information. The model can be formulated as In contrast to ARSA  , where we use a multi-dimensional probability vector produced by S-PLSA to represent bloggers' sentiments  , this model uses a scalar number of blog mentions to indicate the degree of popularity. The accuracy and effectiveness of our model have been confirmed by the experiments on the movie data set. Notice that the semantic features are probabilities while word features are word counts or absolute frequencies. In 16   , a method to systematically derive semantic representation from pLSA models using the method of Fisher kernels 17  has been presented. Cohn and Hofmann combine PLSA and PHITS together and derive a unified model from text contents and citation information of documents under the same latent space 4. As in the experiments in search diversity  , the λ parameter in xQuAD and RxQuAD is chosen to optimize for ERR-IA on each dataset. The TREC 2011 topic set seems the most difficult one. One salient feature of our modeling is the judicious use of hyperparameters  , which can be recursively updated in order to obtain up-to-date posterior distribution and to estimate new model parameters. Our method can not only discover topic milestone papers discussed in previous work  , but also explore venue milestone papers and author milestone papers. One of the advantages of latent variable methods such as ICA  , NMF and PLSA is that they give a parsimonious representation of the data. However  , if interesting longer patterns should be looked for  , ICA and PLSA might be a suitable choice. In essence  , it assumes that there are a number of hidden factors or aspects in the documents  , and models using a probabilistic framework the relationship among those factors  , the documents  , and the words appearing in the documents . Meanwhile  , because traditional evaluation metrics cannot meet the special requirements of QA communities  , we also propose a novel metric to evaluate the recommendation performance. The hidden variables in PLSA correspond to the events that a term w in document d is generated from the j-th topic. Once we created the testing datasets  , we extract topics from the data using both PLSA and NetPLSA. Clearly  , there is significantly fewer cross community edges  , and more inner community conductorships in the communities extracted by NetPLSA than PLSA. In the optional third stage  , we have a review segment ri with multiple sentences and we would like to align all extracted representative opinions to the sentences in ri. From formula 2  , we can see that the aspect model expresses dimensionality reduction by mapping a high dimensional term document matrix into the lower dimensional one k dimension in latent semantic space. In contrast  , Structured PLSA model goes beyond the comments and organizes the head terms by their modifiers  , which could use more meaningful syntactic relations. The 7th to 11th column of Table 1shows the results of the precision of the PLSA-based image selection when the number of topics k varied from 10 to 100. With the rapidly expanding scientific literature  , identifying and digesting valuable knowledge is a challenging task especially in digital library. This can be achieved by extending the basic PLSA to incorporate a conjugate prior defined based on the target paper's abstract and using the Maximum A Posterior MAP estimator . Then all sentences in the collection can be clustered into one of the topic clusters. Our approaches R-LTR-NTN and PAMM-NTN with the settings of using the PLSA or doc2vec as document representations are denoted with the corresponding subscripts. The results indicate that the improvements of R-LTR-NTN plsa and R-LTR-NTN doc2vec over R- LTR are significant p-value < 0.05  , in terms of all of the performance measures. The use of hidden factors provides the model the ability to accommodate the intricate nature of sentiments  , with each hidden factor focusing on one specific aspect. The original ARSA model uses S-PLSA as the component for capturing sentiment information. Practically  , as the latent model is estimated from the observations  , it effectively fuses the sources of information. First  , we employ the PLSA to analyze the topic information of all the questions  , and then model the answerer role and asker role of each user based on questions which he answers or asks. In pLSA  , it is assumed that document-term pairs are generated independently and that term and document identity are conditionally independent given the concept. We propose the S-PLSA model  , which through the use of appraisal groups  , provides a probabilistic framework to analyze sentiments in blogs. To verify that the sentiment information captured by the S-PLSA model plays an important role in box office revenue prediction  , we compare ARSA with two alternative methods which do not take sentiment information into consideration. In contrast to ARSA  , where we use a multi-dimensional probability vector produced by S-PLSA to represent bloggers' sentiments  , this model uses a scalar number of blog mentions to indicate the degree of popularity. Like any topic model based approach  , LapPLSA Laplacian pLSA depends on a prefixed parameter  , the number of topics K. There is no easy solution to find the optimal K without prior knowledge or sufficient training data. While results are relatively stable with respect to γ  , we find that the performance of diversification with topic models is rather sensitive to the parameter K. In Section 6  , we will discuss the impact of K on the diversification results using our framework. Topic modeling approaches employing PLSA have also been used to extract latent themes within a set of articles5   , however this approach is heavyweight and may incorrectly cluster important terms causing them to be missed. For example  , in our data it was shown that conservatives preferred writing " Barrack Hussein Obama " over the liberal " Obama " . The Net- PLSA model15 constructs the u2u-link graph as described in Figure 1a  , merges all documents one user participates in into a single document for that user. The effect of the length of these voting patterns and the number of latent variables in view-specific PLSA models are interesting avenues for future research. TL-PLSA outperforms the other three approaches  , especially in terms of precision  , when there is a large percentage of unshared classes Figure 5. The aim in this paper is to find interesting patterns that characterize the dependencies of the motifs in the data set well or patterns that are surprising  , and to provide a comparison between the methods used. With the smaller yeast data PLSA did not do very well  , but ICA and NMF found interesting longer components and maximal frequent sets gave a good coverage of data. 3 The best performance is achieved by Structured PLSA + Local Prediction at average precision of 0.5925 and average recall of 0.6379. Our particular choice for sentiment modeling is the S-PLSA model 2   , which has been shown to be effective in sales performance prediction. For brevity  , Table 3 shows LIME results for only five parallel sections for " real " inputs too large for simulation  , including one from a benchmark PLSA from bioParallel benchmark 10 that is infeasible to run in simulation. Additionally  , there is no natural way to assign probability to new documents. Additionally  , we show 3 author name variations corresponding to the same person with their probability for each topic. Our intuition is derived from the observation that the data in two domains may share some common topics  , since the two domains are assumed to be relevant. γ allows us to balance these two requirements and combine both implicit and explicit representations of query subtopics in a unified and principled manner. Figure 3 shows the result of IA-select using topic models constructed with the following methods: pLSA without regularization and LapPLSA regularized by similarity matrices generated using click logs  , anchor text  , and Web ngrams  , i.e. Table 4 : Diversification result with pLSA and LapPLSA regularized by different external resources and their combinations. We therefore conclude that In terms of RQ4  , we find that LapPLSA regularized with explicit subtopics tends to outperform the non-regularized pLSA for cases where we do not optimize the setting of K  , and simply choose it at random from a reasonable range. Topic models like PLSA typically operate in extremely high dimensional spaces. As a consequence  , the " curse of dimensionality " is lurking around the corner  , and thus the hyperparameters such as initial conditional probabilities and smoothing parameters settings have the potential to significantly affect the results 1. In PLSA models  , the number of hidden aspect factors is a tuning variable  , while the aspects of Genomics Track topics are constants once the corpus and topics are determined. In order to address the importance of orthogonalized topics  , we put a regularized factor measuring the degree of topic orthogonalities to the objective function of PLSA. Experiments were conducted on an IMDB dataset to evaluate the effectiveness of the proposed approach by comparing the prediction accuracy of ARSA using S-PLSA + and that of the original ARSA. Only over pLSA in MovieLens we observe mixed results  , with xQuAD producing better values on α-nDCG and nDCG-IA respectively  , while RxQuAD is best on ERR-IA  , and pure diversity –as measured by S-precision@r and S-recall. RxQuAD achieves clearer improvements on the popularity baseline . It can be observed that the redundancy penalization effect of | is consistent with the equivalent parameter in the metric  , i.e. In the first stage  , all documents in the collection were used for pLSA learning without making use of the class labels. In the second step  , weak hypotheses are constructed based on both term features and concept features . The wide spread use of blogs as a way of conveying personal views and comments has offered an unique opportunity to understand the general public's sentiments and use this information to advance business intelligence. The data coverage of the components found by each of the methods may seem poor  , but one must remember that we have discarded components consisting of one motif only. We may present the data as a set of latent variables  , and these latent variables can be described either as lists of representative attributes here  , motifs or as lists of representative observations here  , upstream regions. Comparing the obtained results between the three datasets  , we can notice that our approach in SYNC3 and LSHTC datasets achieves similar performance when reducing the percentage of shared classes. Illustrative examples of these results are presented in Table 5  , which summarizes the results of the PLSA model by showing the 10 highest probability words along with their corresponding conditional probabilities from 4 topics in the CiteSeer data set. As expected  , the diversification results of IA-select based on both pLSA and on LapPLSA are sensitive to the change of the parameter K. In particular  , there is no clear correlation between the number of clusters and the end-to-end diversification performance  , which further suggests the difficulty of finding an optimal K that would fit for a set of queries. We can see that the main difference between this equation and the previous one for basic PLSA is that we now pool the counts of terms in the expert review segment with those from the opinion sentences in C O   , which is essentially to allow the expert review to serve as some training data for the corresponding opinion topic. A new concept called " theme " is introduced in TSM for document modeling  , and a theme is modeled as a compound of these three components: neutral topic words  , positive words and negative words  , in each document. From previous experiments  , we have seen that the number of topics K is an important parameter  , whose optimal value is difficult to predict. Instead  , we start with a normalized random distribution for all these conditional probabilities the results reported in this paper are the average of a few runs. We have evaluated the quality of six different topic models ; since the human coding results were obtained as part of a case study for mining ethnic-related content  , two models work specifically with ethnonyms  , but in each case the assessors simply evaluated top words in every topic: We have trained all models with T = 400 topics  , a number chosen by training pLSA models with 100  , 300  , and 400 topics and evaluating the results. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. In fact  , the performance of regularization with click logs is still decent ; testing for significance of the difference between run G C and run pLSA has a p-value of 0.077 for ERR-IA@20 and 0.059 for α-nDCG@20. p-value of 0.1 for ERR-IA@20 and 0.054 for α-nDCG@20  , the highest absolute score is achieved across all settings on this set. Note that at epoch n  , only the new reviews Dn and the current statistics φ n−1 are used to update the S-PLSA + parameters  , and the set of reviews Dn are discarded after new parameter values φ n are obtained  , which results in significant savings in computational resources. The dataset was obtained from the IMDB Website by collecting 28 ,353 reviews for 20 drama films released in the US from May 1  , 2006 to September 1  , 2006  , along with their daily gross box office revenues. However  , this kind of division cannot capture the interrelation between topic and sentiment  , given a document is still modeled as an unordered bag of words; and TSM also suffers from the same problems as in pLSA  , e.g. Second  , PLSA learns about synonyms and semantically related words  , i.e. One problem with all the methods described in this section is that it is not easy to select the parameters defining the amount of components to be looked for. Next  , we calculate the probability of being positive or negative regarding each topic  , P pos|z and P neg|z using pseudo-training images  , assuming that all other candidates images than pseudo positive images are negative samples. This allows the transferring of the learned knowledge to be naturally done even when the domains are different between training and test data. To some extent  , we can consider the Web ngrams more similar to the document content than click logs and anchor text. The common idea of these approaches is that a documentspecific unigram language-model P ,~w can be used to compute for each document the probability to generate a given query. The latter strengthen also our intuition  , that TL-PLSA can learn the shared and unshared classes between domains  , when few documents per class exist  , given a large number of classes as in the SYNC3 and LSHTC datasets. That is  , instead of using the appraisal words  , we train an S-PLSA model with the bag-of-words feature set  , and feed the probabilities over the hidden factors thus obtained into the ARSA model for training and prediction. Note that  , in practice  , it is generally infeasible to consider all the words appearing in the blog entries as potential features   , because the feature set would be extremely large in the order of 100 ,000 in our data set  , and the cost of constructing a document-feature matrix could be prohibitively high. In general  , click logs and anchor text seem to be more valuable resources for regularization compared to Web ngrams  , across different settings of K. Notice that the Web ngrams are primarily derived from document content  , so perhaps their lower effectiveness can be explained by lower influence on pLSA  , which also uses document content. We set the context window size m to 10 unless otherwise stated. The results show our advanced Skipgram model is promising and superior. Further more  , our proposal achieves better performance efficiently and can learn much higher dimensional word embedding informatively on the large-scale data. In our experiments  , we use the gensim implementation of skipgram models 2 . To represent a specific node in S  , previous work tries to find matches in the skipgram model for every phrase  , and average the corresponding vectors 9. Specifically  , in this work we employ the SkipGram algo- rithm 25 which learns word embedding in an unsupervised way by optimizing the vector similarity of each word to context words in a small window around its occurrences in a large corpus. We learned 3 the mapping of 300  , 000 words to a 100-dimension embedded space over a corpus consisting of 7.5 million Web queries  , sampled randomly from a query log. These properties are considered as random influence. The requirement for random access can be accommodated with conventional indexing or hashing methods. One method  , the VP-tree 36  , partitions the data space into spherical cuts by selecting random reference points from the data. With regard to the unexpectedness of the highly relevant results relevancy>=4 Random indexing outperforms the other systems  , however hyProximity offers a slightly more unexpected suggestions if we consider only the most relevant results relevan- cy=5. It offers a scalable approach to the construction of document signatures by applying random indexing 30  , or random projections 3 and numeric quantization. Random " subsequent queries are submitted to the library  , and the retrieved documents are collected. Recently  , several approaches have been developed for selecting references for reference-based indexing 11  , 17. bound3 is the bound obtained using a random point rand inside the hull. 9 proposed a block-based index to improve retrieval speed by reducing random accesses to posting lists. The key of most techniques is to exploit random projection to tackle the curse of dimensionality issue  , such as Locality-Sensitive Hashing LSH 20   , a very well-known and highly successful technique in this area. Finally  , comparing the different reaulta for 11 and A1 in table -4  , it can be aeen that indexing A1 provides better retrieval results than 11. weight 0 random ord. Hence  , in the DocSpace the similarity between documents is computed by the traditional cosine similarity. Users also indicated that Random Indexing provided more general suggestions  , while those provided by hyProximity were more granular. To simulate the distributed environment  , the documents were allocated into 32 different databases using a random allocator with replication. While hyProximity scores best considering the general relevance of suggestions in isolation  , Random Indexing scores best in terms of unexpectedness. This demonstrates the real ability of Linked Data-based systems to provide the user with valuable relevant concepts. With regard to recall  , Random Indexing outperforms the other approaches for 200 top-ranked suggestions. Our indexing structure simply consists of l such LSH Trees  , each constructed with an independently drawn random sequence of hash functions from H. We call this collection of l trees the LSH Forest. The two most important exceptions that require special attention are historical data support and geometric modellii. HyProximity measures improve the baseline across all performance measures  , while Random indexing improves it only with regard to recall and F-measure for less than 200 suggestions. Then  , the distribution of the scores of all documents in a library is modelled by the random variable To derive the document score distribution in step 2  , we can view the indexing weights of term t in all documents in a library as a random variable X t . It is especially useful in cases when it is possible to consider a large number of suggestions which include false positives -such as the case when the keyword suggestions are used for expert crawling. It seems clear that patlems occurring in random indexing can be profitably exploited  , and surprisingly quickly. To build the DocSpace  , Semantic Vectors rely on a technique called Random Indexing 4  , which performs a matrix reduction of the term-document matrix. The gold standard-based evaluation reveals a superior performance of hyProximity in cases where precision is preferred; Random Indexing performed better in case of recall. The shakwat group University of Paris 8 experimented with a random-walk approach using a space built using semantic indexing  , and containing the blog posts  , as well as the headlines  , in a window around the date of the topic. Those models are based on the Harris Harris  , 1968 distributional hypothesis  , which states that words that appear in similar context have similar meanings. For the chosen innovation problem  , the evaluators were presented with the lists of 30 top-ranked suggestions generated by ad- Words  , hyProximity mixed approach and Random Indexing. saving all the required random edge-sets together during a single scan over the edges of the web graph. On the 99-node cluster  , indexing time for the first English segment of the ClueWeb09 collection ∼50 million pages was 145 minutes averaged over three trials; the fastest and slowest running times differed by less than 10 minutes. Details of these datasets appear in Appendix A. The Semantic space method we use in the context of the Blog-Track'09 is Random Indexing RI  , which is not a typical method in the family of Semantic space methods. This representation is finally translated into a binary image signature using random indexing for efficient retrieval. The significance of differences is confirmed by the T-test for paired values for each two methods p<0.05. We then asked them to rate the relevancy and unexpectedness of suggestions using the above described scales. According to the preference towards more general or more specific concepts  , it is therefore possible to advise the user with regard to which of the two methods is more suitable for the specific use case. We used Random Indexing 6  to build distributional semantic representations i.e. The difference in unexpectedness is significant only in the case of Random Indexing vs. baseline. In addition  , our user study evaluation confirmed the superior performance of Linked Data-based approaches both in terms of relevance and unexpectedness. We took great care to match the SHORE/C++ implementation as closely as possible  , including using the same C library random number generator and initializing it with the same seed so as to generate the same sequence of random numbers used to build the OO7 benchmark database and to drive the benchmark traversals. Query type Q1 of the QUERY test represents a sequence of random proximity queries details below. We present two Linked Data-based methods: 1 a structure-based similarity based solely on exploration of the semantics defined concepts and relations in an RDF graph  , 2 a statistical semantics method  , Random Indexing  , applied to the RDF in order to calculate a structure-based statistical semantics similarity. We tested the differences in relevance for all methods using the paired T-test over subjects individual means  , and the tests indicated that the difference in relevance between each pair is significant p <0.05. Therefore  , starting with S1 document removal  , we began by indexing a random selection of 10% of the documents from the document collection. We show later that the ALSH derived from minhash  , which we call asymmetric minwise hashing MH-ALSH  , is more suitable for indexing set intersection for sparse binary vectors than the existing ALSHs for general inner products. In general  , our methods start from a set of Initial/seed Concepts IC  , and provide a ranked list of suggested concepts relevant to IC. Commercial systems like AltaVista Image Search only index the easy-to-see image captions like text-replacement  " ALT "  strings  , achieving good precision accuracy in the images they retrieve but poor recall thoroughness in finding relevant images. For instance  , in a sample of 38720 documents drawn at random from the Online Public Access Catalogue OPAC of the Universitätsbibliothek at Karlsruhe University TH  , 11594 approximately 30% had no keyword  , although the library has the reputation for having the best catalogue in Germany. The first method called hyProximity  , is a structure-based similarity which explores different strategies based on the semantics inherent in an RDF graph  , while the second one  , Random Indexing  , applies a well-known statistical semantics from Information Retrieval to RDF  , in order to identify the relevant set of both direct and lateral topics. As the baseline we use the state of the art adWords keyword recommender from Google that finds similar topics based on their distribution in textual corpora and the corpora of search queries. We rst describe  , in the next section  , how collection indexing was performed. In order to compare to DBSCAN  , we only use the number of points here since DBSCAN can only cluster points according to their spatial location. Moreover  , DBSCAN requires a human participant to determine the global parameter Eps. DBSCAN parameters were set to match the expected point density of the bucket surface. Basically  , DBSCAN is based on notion of density reachability. DBSCAN must set Eps large enough to detect some clusters. proposed the Incremental-DBSCAN in 2. introduced an incremental version of DBSCAN 10. DBSCAN makes use of an R* tree to achieve good performance. The authors illustrate that DBSCAN can be used to detect clusters of any shape and can outperform CLARANS by a large margin up to several orders of magnitude. In DBSCAN a cluster is defined as a set of densely-connected points controlled by  which maximize density-reachability and must contain at least M inP ts points. Since a cluster in DBSCAN contains at least one core object  , MinP ts also defines the minimum number of objects in a cluster. DBSCAN has two parameters: Eps and MinPts. K to approximate the result of DBSCAN. The value that results in the best performance is shown in the graphs for DBSCAN. It uses R*-tree to achieve better performance. The consolidated stoppage points are subsequently clustered using a modified DBSCAN technique to get the identified truck stops. Clusters are then formed based on these concepts. 14  recently analyze places and events in a collection of geotagged photos using DBSCAN. DBSCAN expands a cluster C as follows. On the flip side  , DBSCAN can be quite sensitive to the values of eps and MinPts  , and choosing correct values for these parameters is not that easy. We define the speed-upfuctor as the ratio of the cost of DBSCAN applied to the database after all insertions and deletions and the cost of m calls of IncrementalDBSCAN once for each of the insertions resp. Applied to the gene expression data  , DBSCAN found 6 relatively large clusters where the fraction of genes with functional relationships was rather small. We estimate that DBSCAN also runs roughly 15 times faster and show the estimated running time of DBSCAN in the following table as a function of point set cardinality. In this paper  , we assumed that the parameter values Eps and MinPts of DBSCAN do not change significantly when inserting and deleting objects. The figures depict the resulting clusters found by DBSCAN for two different values for and a fixed value for M inP ts; noise objects in these figures are shown as circles. However  , it requires the setting of two parameters: DBSCAN does not require the definition a-priori of the number of clusters to extract. The results and evaluations are reported in Section 5. Now  , we can calculate the speed-up factor of IncrementalDBSCAN versus DBSCAN. First  , our proposal performs consistently better than the best DBScan results obtained with cmin = 3. In DBSCAN  , the density concept is introduced by the notations: Directly density-reachable  , Density-reachable  , and Densityconnected . However  , because objects are organized into lineal formations  , the larger Eps is  , the larger void pad is. Each cluster is a maximum set of density-connected points. We implemented PreDeCon as well as the three comparative methods DBSCAN  , PROCLUS  , and DOC in JAVA. CHAMELEON requires the setting of the number of clusters to he sought  , which is generally not known. We can see that DBSCAN is 2-3 times slower than both SPARCL and Chameleon on smaller datasets. Eps and MinPts " in the following whenever it is clear from the context. In the case of DBSCAN the index finds the correct number of clusters that is three. Comparison with DBSCAN. Concluding remarks are offered in Section 4. DBSCAN proved very sensitive to the parameter settings. The resulting point cloud is a smooth continuous surface with all outliers removed. Scalability experiments were performed on 3d datasets as well. The tripwise LTD file records are indexes of consolidated stoppages made during trips. The DBSCAN technique was modified with KD-trees to reduce the computational complexity. The local clusters are represented by special objects that have the best representative power. Note that the definition of " Noise " is equivalent to DBSCAN. 1 who propose a hierarchical version of DBSCAN called OPTICS. Figure 1show an example where no global density threshold exists that can separate all three natural clusters  , and consequently  , DBSCAN cannot find the intrinsic cluster structure of the dataset. Table 2. shows an example of records that could be mistakenly clustered together by DBSCAN without an integrity check. However  , there may be applications where this assumption does not hold  , i.e. These outliers were removed using DBSCAN to identify low density noise. Of course  , in this example DBSCAN itself could have found the two clusters. DBSCAN successfully identifies different types of patterns of user-system interaction that can be interpreted in light of how users interact with WorldCat. k since for each core point there are at least MinPts points excluding itself within distance Eps. Streemer on the other hand first finds candidate clusters and then only merges them if the resulting cluster is highly cohesive. A region query returns all objects intersecting a specified query region. An object o is directly density reachable from another object o if it is not farther away than a given density radius ε and o is surrounded more than θ objects. The distribution of these points is shown in Fig 9. DBSCAN is used to cluster the entire data set. For OP- TICS  , M inP ts is set to a fixed value so that density-based clusters of different densities are characterized by different values for . Then  , DBSCAN visits the next object of the database D. The retrieval of density-reachable objects is performed by successive region queries.  We complement our quantitative evaluation with a qualitative one Section 5. But in high-dimensional spaces the parameter ε specifying the density threshold must be chosen very large  , because a lot of dimensions contribute to the distance values. So MinP ts must be large enough to distinguish noise and clusters. In our application of DBSCAN  , all the terms in documents were tokenized  , stemmed using Porter stemmer  , and stopwords were removed. Distance between documents was computed as 1 -cosine similarity. Advantages of these schemes include the ability to segment non convex shapes  , identify noise  , and automatically estimate the number of partitions in a data set. In Section 4 we introduce DBSCAN with constraints and extend it to run in online fashion. To find a cluster  , DBSCAN starts with an arbitrary object p in D and retrieves all objects of D density-reachable from p with respect to Eps and MinPfs. In this example  , P-DBSCAN forms better clusters since it takes local density into account. For each run of DBSCAN on the biological data sets  , we chose the parameters according to 5 using a k-nn-distance graph. The main advantages of DBSCAN are that it does not require the number of desired clusters as an input  , and it explicitly identifies outliers. However  , even for these small datasets  , the spectral approach ran out of memory. Table 1 summarizes the clusters and shows mean values for the original features  , as well as stability scores. In relation to DBSCAN unstable clusters represent data points that should either have formed part of another cluster or should have been classified as noise. Aside from being easy to implement and having an agreeable time complexity  , DBSCAN has many relevant advantages including its capacity to form arbitrarily shaped clusters and to automatically detect outliers. DBSCAN's ability to distinguish between points of varying density is limited while SNN can identify uniformly low density clusters by analysing the shared nearest neighbours between points. Knowledge of previous objects can be maintained for short durations if temporally occluded or when an object is missed due to the number of matched key-points dropping below the minP ts threshold required by DBSCAN. Streemer also requires similar parameters  , but we found that it is not sensitive to them. Obviously  , the larger void pad is  , the more chance to include noise data into a cluster  , which can cause chain affection   , and hence lower quality of density. DBSCAN is a typical density-based method which connects regions with sufficiently high density into clusters. As we can see SPARCL also perfectly identifies the shape-based clusters in these datasets. In this section we present the empirical results of SSDB- SCAN and compare it with DBSCAN and HISSCLU. According to the density-based definition  , a cluster consists of the minimum number of points MinPts to eliminate very small clusters as noise; and for every point in the cluster  , there exists another point in the same cluster whose distance is less than the distance threshold Eps points are densely located. From results presented in Section 4  , the indications are that the most unstable clusters clusters 8  , 9 and 10 should probably have formed part of other more stable clusters. One possible reason for this could be the fact that the parameter of DBSCAN is a global parameter and cannot be adjusted per-cluster. Points with fewer than minP ts in their ǫ neighbourhood are considered as noise within the DBSCAN framework  , unless on the boundary of a dense cluster. This classifier is initialised with the initial clusters found in the first pair of frames and then incrementally updated there after. In a data warehouse  , however  , the databases may have frequent updates and thus may be rather dynamic. The night sky is one example; as the magnification level is adjusted  , one will identify different groupings or clusters. Figure 2illustrates results of FIRES in comparison to SUBCLU  , and CLIQUE applied on a synthetic dataset containing three clusters of significantly varaying dimensionality and density. Parameter values of = 0.4 and M inP ts = 200 were chosen through empirical investigation. Previous work in person name disambiguation can be generally be categorized as either supervised or unsupervised approaches. For instance  , Deng  , Chuang  , and Lemmens  , 2009 use DBSCAN to cluster Flickr photos   , and they exploit tag co-occurrence to characterize the discovered clusters. Additionally  , if we were to pick the minimum-cost solution out of multiple trials for the local search methods  , the differences in the performance between BBC-Press vs. DBSCAN and Single Link becomes even more substantial  , e.g. We made similar observations when we applied DB- SCAN to the metabolome data: the computed clusters contained newborns with all sorts of class labels. Finally  , the notion of the representative trajectory of a cluster is provided. The problem of finding global density parameters has also been observed by Ankerst et al. DBSCAN produced a group of 10 clusters from the log data with around 20% classified as 'noise' – points too far away from any of the produced clusters to be considered for inclusion and discarded from further analyses. However   , before drawing inferences from the resulting clusters it is essential to validate the results to reduce the possibility that the clusters were identified by chance and do not actually reflect differences in the underlying data. Furthermore  , our work combines a streaming DBSCAN method along with constraints requirements that are not only at the instance level  , but also at the cluster level. As a result  , the result of STING approaches that of DBSCAN when the granularity approaches zero. Such queries are supported efficiently by spatial access methods such as R*trees BKSS 903 for data from a vector space or M-trees 4 IncrementalDBSCAN DBSCAN  , as introduced in EKSX 961  , is applied to a static database. The performance difference between our method BBC-Press and the other three methods is quite significant on all the five datasets  , given the small error bars. Density-based techniques like DBSCAN 4  , OPTICS 2 consider the density around each point to demarcate boundaries and identify the core cluster points. We apply DBSCAN to generate the baseclusters using a parameter setting as suggested in 8 and as refinement method with paramter settings for ε and minpts as proposed in Section 3.4. In our experiments  , it only requires 3 minutes to deal with one-day user logs of 150 ,000 queries. With respect to RQ2 cluster stability scores can be used help determine the optimum number of clusters and evaluate the " goodness " of the resulting clusters 7. When setting the speed-up factor to 1.0  , we obtain the number of updates denoted by MaxUpdates up to which the multiple application of IncrementalDBSCAN for each update is more efficient than the single application of DBSCAN to the whole updated database. For DBSCAN we do not show the results for DS4 and Swiss-roll since it returned only one cluster  , even when we played with different parameter set- tings. Since there are a lot of noise data  , DBSCAN with larger Eps is likely to include those noise data and cause chain affection  , forming serval larger clusters instead of small individual clusters. We also observed that the relative performance between U-AHC and F OPTICS  , and between F DBSCAN and U-AHC did not substantially vary with the dataset. Figure 10depicts the values of MaxUpdates depending on n for fde values of up to 0.5 which is the maximum value to be expected in most real applications. Probabilistic facts model extensional knowledge. This enables a principled integration of the thesaurus model and a probabilistic retrieval model. Relevance measurements were integrated within a probabilistic retrieval model for reranking of results.  In the language model approaches to information retrieval  , models that capture term dependencies achieve substantial improvements over the unigram model. Our suggested probabilistic methods are also able to retrieve per-feature opinions for a query product. The model builds a simple statistical language model for each document in the collection. Traditional information retrieval models are mainly classified into classic probabilistic model  , vector space model and statistical language model. Probabilistic Information Retrieval IR model is one of the most classical models in IR. This paper presented the linguistically motivated probabilistic model of information retrieval. In here  , we further developed and used a fully probabilistic retrieval model. Furthermore. Then we present a probabilistic object-oriented logic for realizing this model  , which uses probabilistic Datalog as inference mechanism. We argue that the current indexing models have not led to improved retrieval results. Ponte and Croft first applied a document unigram model to compute the probability of the given query generated from a document 9. The retrieval was performed using query likelihood for the queries in Tables 1 and 2  , using the language models estimated with the probabilistic annotation model. Sound statistic background of the model brings its outstanding performance. This model shows that documents should be ranked according to the score These dependencies are used in a retrieval strategy based on the probabilistic model described in CROF86a. BIR: The background model comprises several sequences of judgements. This in contrast with the probabilistic model of information retrieval . A notable feature of the Fuhr model is the integration of indexing and retrieval models. We use different state-of-the-art keyword-based probabilistic retrieval models such as the sequential dependence model  , a query likelihood model  , and relevance model query expansion . The linkage weighting model based on link frequency can substantially and stably improve the retrieval performances. This evaluation can only be performed for the probabilistic annotation model  , because the direct retrieval model allows us only to estimate feature distributions for individual word images  , not page images. An effective thesaurus-based technique must deal with the problem of word polysemy or ambiguity  , which is particularly serious for Arabic retrieval. Ponte and Croft first applied a document unigram model to compute the probability of the given query to be generated from a document 16. The SMART information retrieval system  , originally developed by Salton  , uses the vector-space model of information retrieval that represents query and documents as term vectors. The following equations describe those used as the foundation of our retrieval strategies. In this work  , we show that the database centric probabilistic retrieval model has various interesting properties for both automatic image annotation and semantic retrieval. The probabilistic model of retrieval 20 does this very clearly  , but the language model account of what retrieval is about is not that clear. The proposed probabilistic models of passage-based retrieval are trained in a discriminative manner . However  , accurately estimating these probabilities is difficult for generative probabilistic language modeling techniques. Instead of the vector space model or the classical probabilistic model we will use a new model  , called the linguistically motivated probabilistic model of information retrieval  , which is described in the appendix of this paper. It is generally agreed that the probabilistic approach provides a sound theoretical basis for the development of information retrieval systems. We define the parameters of relevant and non-relevant document language model as θR and θN . We model the relevant model and non-relevant model in the probabilistic retrieval model as two multinomial distributions. A model of a retrieval situation with PDEL contains two separate parts  , one epistemic model that accomodates the deterministic information about the interactions and one pure probabilistic model. The about predicate says that d1 is about 'databases' with 0.7 probability and about 'retrieval' with 0.5 probability . The rule retrieve means that a document should be retrieved when it is about 'databases' or 'retrieval'. We provide a probabilistic model for image retrieval problem. Therefore  , in a probabilistic model for video retrieval shots are ranked by their probability of having generated the query. However  , applying the probabilistic IR model into legal text retrieval is relatively new. query terms rather than document terma because they were investigating probabilistic retrieval Model 2 of Robertson et.al. The incrementing of document scores in this way is ba.sed on a probabilistic model of retrieval described in Croft's paper. Technical details of the probabilistic retrieval model can be found in the appendix of this paper. After obtaining   , another essential component in Eqn. the probabilistic model offers justification for various methods that had previously been used in automatic retrieval environments on an empirical basis. If a query consists of several independent parts e.g. We present a probabilistic model for the retrieval of multimodal documents. We will revisit and evaluate some representative retrieval models to examine how well they work for finding related articles given a seed article. With weight parameters  , these can be integrated into one distribution over documents  , e.g. In ROBE81 a similar retrieval model  , the 80 251 called two-poisson-independence TPI model is described. To derive our probabilistic retrieval model  , we first propose a basic query formulation model.  Our dependence model outperforms both the unigram language model and the classical probabilistic retrieval model substantially and significantly. Many models for ranking functions have been proposed previously  , including vector space model 43   , probabilistic model 41 and language model 35 . In the information retrieval domain  , the systems are based on three basic models: The Boolean model  , the vector model and the probabilistic model. 10 uses a 2-Poisson model for including term frequency-based probabilities in the probabilistic retrieval model. The novelty of our work lies in a probabilistic generation model for opinion retrieval  , which is general in motivation and flexible in practice. navigation-aided retrieval constitutes a strict generalization of the conventional probabilistic IR model. We conducted numerous calibrations using the vector space model Singhal96  , Robertson's probabilistic retrieval strategy Robertson98  , and a modified vector space retrieval strategy. The probabilistic retrieval model is attractive because it provides a theoretical foundation for the retrieval operation which takes into account the notion of document relevance. In the next section  , we describe related work on collection selection and merging of ranked results. 6 identify and classify temporal information needs based on the relevant document timestamp distribution to improve retrieval. This paper looks at the three grand probabilistic retrieval models: binary independent retrieval BIR  , Poisson model PM  , and language modelling LM. Query likelihood retrieval model 1  , which assumes that a document generates a query  , has been shown to work well for ad-hoc information retrieval. The model supports probabilistic indexing 9  , however we implement a simplified version in which only estimates of O or 1 are used for the probability that a document has a feature. Eri can be determined by a point estimate from the specific text retrieval model that has been applied. The probabilistic retrieval model for semistructured data PRM-S 11  scores documents by combining field-level querylikelihood scores similarly to other field-based retrieval mod- els 13. This shows that both the classical probabilistic retrieval model and the language modeling approach to retrieval are special cases of the risk minimization framework. Results include  , for example  , the formalisation of event spaces. Performance on the official TREC-8 ad hoc task using our probabilistic retrieval model is shown in Figure 7. Similar probabilistic model is also proposed in 24  , but this model focuses in parsing noun phrases thus not generally applicable to web queries. Although PRMS was originally proposed for XML retrieval  , it was later applied to ERWD 2. The first probabilistic model captures the retrieval criterion that a document is relevant if any passage in the document is relevant. We start with a probabilistic retrieval model: we use probabilistic indexing weights  , the document score is the probability that the document implies the query  , and we estimate the probability that the document is relevant to a user. In the following  , we investigate three different  , theoretically motivated methods for predicting retrieval quality i.e. To solve the problem  , we propose a new probabilistic retrieval method  , Translation model  , Specifications Generation model  , and Review and Specifications Generation model  , as well as standard summarization model MEAD  , its modified version MEAD-SIM  , and standard ad-hoc retrieval method. One of the main reasons why the probabilistic model bas not been widely accepted is; pemaps  , due to its computational complexity. The term-precision model differs from the previous two weighting systems in that document relevance is taken into account. The thesaurus is incorporated within classical information retrieval models  , such as vector space model and probabilistic model 13. The score function of the probabilistic retrieval model based on the multinomial distribution can be derived from taking the log-odds ratio of two multinomial distributions. In this paper we introduce a probabilistic information retrieval model. Although the most popular is still undoubtedly the vector space model proposed by Salton 19   , many new or complementary alternatives have been proposed  , such as the Probabilistic Model 16. the binary independent retrieval BIR model 15 and some state-of-the-art language models proposed for IR in the literature. Recently  , the PRF principle has also been implemented within the language modeling framework. Overall  , the PLM is shown to be able to achieve " soft " passage retrieval and capture proximity heuristic effectively in a unified probabilistic framework. We further incorporate the probabilistic query segmentation into a unified language model for information retrieval. We proposed a formal probabilistic model of Cross-Language Information Retrieval. In this paper  , we present a Cross Term Retrieval model  , denoted as CRTER  , to model the associations among query terms in probabilistic retrieval models. The retrieval model we use to rank video shots is a generative model inspired by the language modelling approach to information retrieval 2  , 1  and a similar probabilistic approach to image re- trieval 5. We start by formulating the integrated language model with query segmentation based on the probabilistic ranking prin- ciple 15. Given a text query  , retrieval can be done with these probabilistic annotations in a language model based approach using query-likelihood ranking. Classifiers were trained according to the probabilistic model described by Lewis 14  , which was derived from a retrieval model proposed by Fuhr 9. We explain the PRM-S model in the following section. To our knowledge  , no one has yet tried to incorporate such a thesaurus within the language modeling framework. The model is significantly different from other recently proposed models in that it does not attempt to translate either the query or the documents. Both of these models estimate the probability of relevance of each document to the query. We start by developing a formal probabilistic model for the utilization of key concepts for information retrieval. Probabilistic models have been successfully applied in document ranking  , such as the traditional probabilistic model 23  , 13  , 24 and stochastic language model 21  , 15  , 29 etc. The main contribution of our work is a formal probabilistic approach to estimating a relevance model with no training data. The second probabilistic model goes a step further and takes into account the content similarities among passages. Importantly  , our navigation-aided retrieval model strictly generalizes the conventional probabilistic information retrieval model  , which implicitly assumes no propensity to navigate formal details are provided in Section 3. In the second model  , which we call the " Direct Retrieval " model  , we take each text query and compute the probability of generating a member of the feature vocabulary. The main techniques used in our runs include medical concept detection  , a vectorspace retrieval model  , a probabilistic retrieval model  , a supervised preference ranking model  , unsupervised dimensionality reduction  , and query expansion. The details of these techniques are given in the next section. 39 This last model appears to be computationally difficult  , but further progress may be anticipated in the design and use of probabilistic retrieval models. The main difference between the TPI model and the RPI model is that the RPI model is suited to different probabilistic indexing models  , whereas the TPI model is an ex~ension of the two-poisson model for multi-term queries. The contribution that each of the top ranked documents makes to this model is directly related to their retrieval score for the initial query. In this section  , we apply the six constraints defined in the previous section to three specific retrieval formulas  , which respectively represent the vector space model  , the classical probabilistic retrieval model  , and the language modeling approach. Most of the existing retrieval models assume a " bag-of-words " representation of both documents and queries. We have presented a new dependence language modeling approach to information retrieval. Coming back to Figure 1  , notice that certain hyperlinks are highlighted i.e. In this paper we present a novel probabilistic information retrieval model and demonstrate its capability to achieve state-of-the-art performance on large standardized text collections. The retrieval model integrates term translation probabilities with corpus statistics of query terms and statistics of term occurrences in a document to produce a probability of relevance for the document to the query. We discussed a model of retrieval that bridges a gap between the classical probabilistic models of information retrieval  , and the emerging language modeling approaches. For relevant task  , a multi-field relevance ranking based on probabilistic retrieval model has been used. 2 integrate temporal expressions in documents into a time-aware probabilistic retrieval model. We then proceed to detail the supervised machine learning technique used for key concept identification and weighting. Rules model intensional knowledge  , from which new probabilistic facts are derived. 3.2.1 Unigram language models: In the language modelling framework  , document ranking is primarily based on the following two steps. Canfora and Cerulo 2 searched for source files through change request descriptions in open source code projects. In this paper the different disambiguation strategies of the Twenty-One system will be evaluated. However  , it is worth mentioning that the proposed method is generally applicable to any probabilistic retrieval model. In blog seed retrieval tasks  , we are interested in finding blogs with relevant and recurring interests for given topics . Traditional IR probabilistic models  , such as the binary independence retrieval model 11  , 122 focus on relevance to queries. For example  , the useful inverse document frequency  idf term weighting system. Results from our integrated approach outperformed baseline results and exceeded the top results reported at the TREC forum  , demonstrating the efficacy of our approach. However   , the utilization of relevant information was one of the most important component in Probabilistic retrieval model. In the probabilistic retrieval model used in this work  , we interpret the weight of a query term to be the frequency of the term being generated in query generation. Review and Specifications Generation model ReviewSpecGen considers both query-relevance and centrality  , so we use it as another baseline method. Thk paper describes how these issues can be addressed in a retrieval system based on the inference net  , a probabilistic model of information retrieval. A new probabilistic generative model is proposed for the generation of document content as well as the associated social annotations. Furthermore  , our empirical work suggests that in the case of unambiguous queries for which conventional IR techniques are sufficient  , NAR reduces to standard IR automatically. They use both a probabilistic information retrieval model and vector space models. This is the second year that the IR groups of Tsinghua University participated in TREC Blog Track. In our model  , both single terms and compound dependencies are mathematically modeled as projectors in a vector space  , i.e. We further leverage answers to a question to bridge the vocabulary gap between a review and a question. The robustness of the approach is also studied empirically in this paper. The basic idea is that there is uncertainty in the prediction of the ranking lists of images based on current visual distances of retrieved images to the query image. For example   , probabilistic models are a common type of model used for IR. Conclusions and the contributions of this work are summarized in Section 6. This paper defines a linguistically motivated model of full text information retrieval. Other QBSD audition systems 19  , 20  have been developed for annotation and retrieval of sound effects. The top ranked m collections are chosen for retrieval . In this paper  , we proposed a novel probabilistic model for blog opinion retrieval. Current experiments deal with the following topics: probabilistic retrieval binary independent model  , automatic weighting  , morphological segmentation  , efficiency of thesaurus organization  , association measures reconsidered. For example  , paper D  , " A proximity probabilistic model for information retrieval " mentions both A and B. In our hypothetical example  , A has only a handful of citation contexts which we would like to expand to better describe paper A. Figure 4shows the interpolated precision scores obtained with the probabilistic annotation and direct retrieval model. In this paper  , we propose a probabilistic entity retrieval model that can capture indirect relationships between nodes in the RDF graph. In sum  , this probabilistic retrieval model considers the relevance at three different levels: document  , passage and entity. According to one model Collection-centric  , each collection is represented as a term distribution computed over its contents. In the following  , the probabilistic model for distributed IR is experimentally evaluated with respect to the retrieval effectiveness . RSJ relevance weighting of query terms was proposed in 1976 5 as an alternative term weighting of 2 when relevant information is available. Evaluation is a difficult problem since queries and relevance judgements are not available for this task. These two probabilistic models for the document retrieval problem grow out of two different ways of interpreting probability of relevance. Intermediate results imply that accepted hypotheses have to be revised. The comparison of our approach to both the probabilistic retrieval models and the previous language models will show that our model achieves substantial and significant improvements. The probabilistic retrieval model also relies on an adjustment for document length 3. To perform information retrieval  , a label is also associated with each term in the query. These dependencies are used in a retrieval strategy based on the probabilistic model described in CROF86a. The experiments show that with our estimate of the relevance model  , classical probabilistic models of retrieval outperform state-of-the-art heuristic and language modeling approaches. As boolean retrieval is in widespread use in practice  , there are attempts to find a combination with probabilistic ranking procedures. In classical probabilistic IR models  , such as the binary independence retrieval BIR model 18  , both queries and documents are represented as a set of terms that are assumed to be statistically independent. Our first probabilistic model captures the retrieval criterion that a document is relevant if any passage of the document is relevant and models individual passages independently. Our experiments on six standard TREC collections indicate the effectiveness of our dependence model: It outperforms substantially over both the classical probabilistic retrieval model and the state-of-the-art unigram and bigram language models. This type of model builds a probabilistic language model G d for each document d  , and then ranks documents for a given query based on the likelihood that each document's language model could have generated the query: P q|G d . These models were derived within many variations extended Boolean models  , models based on fuzzy sets theory  , generalized vector space model ,. It is more flexible then the BU model  , because it works with two concepts: 'correctneu' aa a basis of the underlying indexing model  , and 'relevance' for ·the retrieval parameters. Since the first model estimates the probability of relevance for each passage independently  , the model is called the independent passage model. Probabilistic Retrieval Model for Semistructured Data PRMS 14  is a unigram bag-ofwords model for ad-hoc structured document retrieval that learns a simple statistical relationship between the intended mapping of terms in free-text queries and their frequency in different document fields. Unlike some traditional phrase discovery methods  , the TNG model provides a systematic way to model topical phrases and can be seamlessly integrated with many probabilistic frameworks for various tasks such as phrase discovery   , ad-hoc retrieval  , machine translation  , speech recognition and statistical parsing. We proposed several methods to solve this problem  , including summarization-based methods such as MEAD and MEAD-SIM and probabilistic retrieval methods such as Specifications Generation model  , Review and Specifications Generation model  , and Translation model. One component of a probabilistic retrieval model is the indexing model  , i.e. To the former we owe the concept of a relevance model: a language model representative of a class of relevant documents. In a very recent work 4  , the author proposed a topic dependent method for sentiment retrieval  , which assumed that a sentence was generated from a probabilistic model consisting of both a topic language model and a sentiment language model. An important advantage of introducing a language model for each position is that it can allow us to model the " best-matching position " in a document with probabilistic models  , thus supporting " soft " passage retrieval naturally. The retrieval function is: This type of model builds a probabilistic language model G d for each document d  , and then ranks documents for a given query based on the likelihood that each document's language model could have generated the query: P q|G d . A second sense of the word 'model' is the probabilistic sense where it refers to an explanatory model of the data. The TPI model makes more use of the specific assumption of the indexing model  , 80 that for any other indexing model a new retrieval model would have to be developed. But in order to consider the special nature of annotations for retrieval  , we proposed POLAR Probabilistic Object-oriented Logics for Annotation-based Retrieval as a framework for annotation-based document retrieval and discussion search 8 . A model of randomness is derived by a suitable interpretation of the probabilistic urn models of Types I and II 4 i n to the context of Information Retrieval. 10 on desktop search  , which includes document query-likelihood DLM  , the probabilistic retrieval model for semistructured data PRM-S and the interpolation of DLM and PRM-S PRM-D. We suggested why classical models with their explicit notion of relevance may potentially be more attractive than models that limit queries to being a sample of text. for the distribution of visual features given the semantic class.  published search reports can be used to learn to rank and provide significant retrieval improvements ? In information retrieval there are three basic models which are respectively formulated with the Boolean  , vector  , and probabilistic concepts. Two retrieval runs were submitted: one consisting of the title and description sections only T+D and the other consisting of all three title  , description  , and narrative sections T+D+N. We show examples of extracted phrases and more interpretable topics on the NIPS data  , and in a text mining application  , we present better information retrieval performance on an ad-hoc retrieval task over a TREC collection. The 2006 legal track provides an uniform simulation of legal text requests in real litigation  , which allows IR researchers to evaluate their retrieval systems in the legal domain. In some cases  , our structured queries even attain a better retrieval performance than the title queries on the same topic. As described in Section 3  , the frequency is used as an exponent in the retrieval function. Among many variants of language models proposed  , the most popular and fundamental one is the query-generation language model 21  , 13  , which leads to the query-likelihood scoring method for ranking documents. One of the important properties of the database centric probabilistic retrieval formulation is that  , due to the simplicity of the retrieval model  , it enables the implementation of sophisticated parameter optimization procedures. One major goal of us is to evaluate the effect of a probabilistic retrieval model on the legal domain. The vector space model as well as probabilistic information retrieval PIR models 4  , 28  , 29 and statistical language models 14 are very successful in practice. In the probabilistic retrieval model 2  , for instance  , it is assumed that indexing is not perfect in the sense that there exists relevant and nonrelevant documents with the same description. Blog post opinion retrieval is the problem of finding blog posts that express opinion about a given query topic. Results show that in most test sets  , LDM outperforms significantly the state-of-the-art LM approaches and the classical probabilistic retrieval model. Our approach provides a conceptually simple but explanatory model of re- trieval. Thus  , our method demonstrates an interesting meld of discriminative and generative models for IR. This system is based on a supervised multi-class labeling SML probabilistic model 1  , which has shown good performance on the task of image retrieval. The dependencies derived automatically from Boolean queries show only a small improvement in retrieval effectiveness. Traditional probabilistic relevance frameworks for informational retrieval 30  refrain from taking positional information into account  , both because of the hurdles of developing a sound model while avoiding an explosion in the number of parameters and because positional information has been shown somehow surprisingly to have little effect on aver- age 34 . For example  , given the fundamentally different from these efforts is the importance given to word distributions: while the previous approaches aim to create joint models for words and visual features some even aim to provide a translation between the two modalities 7  , database centric probabilistic retrieval aims for the much simpler goal of estimating the visual feature distributions associated with each word. The model assumes that the relevance relationship between a document and a user's query cannot be determined with certainty. For many of the past TREC experiments  , our system has been demonstrated to provide superior effectiveness  , and last year it was observed that PIRCS is one of few automatic systems that provides many unique relevant documents in the judgment pool VoHa98. We design the model based on the assumption that the descriptions of an entity exist at any literal node that can be reached from the resource entity node by following the paths in the graph. Two well known probabilistic approaches to retrieval are the Robertson and Sparck Jones model 14 and the Croft and Harper model 3 . It has been observed that in general the classical probabilistic retrieval model and the unigram language model approach perform very similarly if both have been fine-tuned. The retrieval model scores documents based on the relative change in the document likelihoods   , expressed as the ratio of the conditional probability of the document given the query and the prior probability of the document before the query is specified. Cooper's paper on modeling assumptions for the classical probabilistic retrieval model 2. For page retrieval  , these annotation probability distributions are averaged over all images that occur in a page  , thus creating a language model of the page. Language modeling approaches apply query expansion to incorporate information from Lafferty and Zhai 7 have demonstrated the probability equivalence of the language model to the probabilistic retrieval model under some very strong assumptions  , which may or may not hold in practice. While tbe power of this model yields strong retrieval effectiveness  , the structured queries supported by the model present a challenge when considering optimization techniques. Antoniol  , Canfora  , Casazza  , DeLucia  , and Merlo 3 used the vector space model and a probabilistic model to recover traceability from source code modules to man pages and functional requirements. We chose PIR models because we could extend them to model data dependencies and correlations the critical ingredients of our approach in a more principled manner than if we had worked with alternate IR ranking models such as the Vector-Space model. In the use of language modeling by Ponte and Croft 17  , a unigram language model is estimated for each document  , and the likelihood of the query according to this model is used to score the document for ranking. The Mirror DBMS uses the linguistically motivated probabilistic model of information retrieval Hie99  , HK99. We currently concentrate on system design and integration. This paper will demonstrate that these advantages translate directly into improved retrieval performance for the routing problem. It is a probabilistic model that considers documents as binary vectors and ranks them in order of their probability of relevance given a query according to the Probability Ranking Principle 2. The main feature of the PRM-S model is that weights for combining field-level scores are estimated based on the predicted mapping between query terms and document fields  , which can be efficiently computed based on collection term statistics. In this section  , we propose a non-parametric probabilistic model to measure context-based and overall relevance between a manuscript and a candidate citation  , for ranking retrieved candidates. This work is also closely related to the retrieval models that capture higher order dependencies of query terms. Thus  , our PIRCS system may also be viewed as a combination of the probabilistic retrieval model and a simple language model. The proposed model is guided by the principle that given the normalized frequency of a term in a document   , the score is proportional to the likelihood that the normalized tf is maximum with respect to its distribution in the elite set for the corresponding term. The PLM at a position of a document would be estimated based on the propagated word counts from the words at all other positions in the document. Lafferty and Zhai 7 have demonstrated the probability equivalence of the language model to the probabilistic retrieval model under some very strong assumptions  , which may or may not hold in practice. Next  , we improve on it by employing a probabilistic generative model for documents  , queries and query terms  , and obtain our best results using a variant of the model that incorporates a simple randomwalk modification. This paper focuses on whether the use of context information can enhance retrieval effectiveness in retrospective experiments that use the statistics of relevance information similar to the w4 term weight 1  , the ratio of relevance odds and irrelevance odds. This paper discusses an approach to the incorporation of new variables into traditional probabilistic models for information retrieval  , and some experimental results relating thereto. Research on disambiguating senses of the translated queries and distributing the weighting for each translation candidate in a vector space model or a probabilistic retrieval model 3 will be the primary focus in the second phase of the MUST project. However  , as any retrieval system has a restricted knowledge about a request  , the notation /A: used in the probabilistic formulas below does not relate to a single request  , it stands for a set of requests about which the system has the same knowledge. If Model 3 constitutes a valid schema for this kind of a search situation  , we see that it should be applicable not only to the document retrieval problem but for other kinds of search and retrieval situations as well. These dependent term groups were then used to modify the rankings of documents retrieved by a probabilistic retrieval  , as was done in CROVS6a. Among the applications for a probabilistic model are i accurate search and retrieval from Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Our performance experiments demonstrate the efficiency and practical viability of TopX for ranked retrieval of XML data. In information retrieval domain  , systems are founded on three basic ones models: The Boolean model  , the vector model and the probabilistic model which were derived within many variations extended Boolean models  , models based on fuzzy sets theory  , generalized vector space model ,. Basically  , a model of Type I is a model where balls tokens are randomly extracted from an urn  , whilst in Type II models balls are randomly extracted from an urn belonging to a collection of urns documents. In 1976 Robertson and Sparck Jones proposed a second probabilistic model which we shall refer to as Model 2 for the document retrieval problem. To evaluate relevance of retrieved opinion sentences in the situation where humanlabeled judgments are not available  , we measured the proximity between the retrieved text and the actual reviews of a query product. 5 Model 2 interprets the information seeking situation in the usual way as follows: The documents in the collection have a wide variety of different properties; semantic properties of aboutness  , linguistic properties concerning words that occur in their titles or text  , contextual properties concerning who are their authors  , where they were published   , what they cited  , etc. The database centric probabilistic retrieval model is compared to existing semantic labeling and retrieval methods  , and shown to achieve higher accuracy than the previously best published results  , at a fraction of their computational cost. However  , diaeerent research communities have associated diaeerent partially incompatiblee interpretations with the values returned from such score functions   , such astThe fuzzy set interpretation ë2  , 8ë  , the spatial interpretation originally used in text databases  , the metric interpetation ë9ë  , or the probabilistic interpretation underlying advanced information retrieval systems ë10ë. The classical probabilistic retrieval model 16  , 13  of information retrieval has received recognition for being theoreti- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Recently  , though  , it has been proved that considering sequences of terms that form query concepts is beneficial for retrieval 6. We propose a formal probabilistic model for incorporating query and key concepts information into a single structured query  , and show that using these structured queries results in a statistically significant improvement in retrieval performance over using the original description queries on all tested corpora. Following 21  , we define a theme as follows: Definition 1 Theme A theme in a text collection C is a probabilistic distribution of words characterizing a semantically coherent topic or subtopic. According to one model Collection-centric  , each collection is represented as a term distribution  , which is estimated from all sampled documents. The framework is very general and expressive  , and by choosing specific models and loss functions it is possible to recover many previously developed frameworks. We focused on the problem of opinion topic relatedness and we showed that using proximity information of opinionated terms to query terms is a good indicator of opinion and query-relatedness. In Bau99  , the procedure for estimating the addends in equation 2 is exemplarily shown for the mentioned BIR as well as the retrieval-with-probabilistic-indexing RPI model Fuh92. In fact  , most of the known non-distributed probabilistic retrieval models propose a RSV computation that is based on an accumulation over all query features. We first utilize a probabilistic retrieval model to select a smaller set of candidate questions that are relevant to a given review from a large pool of questions crawled from the CQA website. In summary  , this probabilistic retrieval model considers the relevance at three different levels: document  , passage and entity. ing e.g. The strategy developed from the probabilistic model by Croft CROFS1 ,CROF86a 1 can make use of information about the relative importance of terms and about dependencies between terms. Figure 2 shows the recallprecision curves for the results of executing 19 queries with the two retrieval mechanisms LSA and probabilistic model supported in CodeBroker. In this paper we: i present a general probabilistic model for incorporating information about key concepts into the base query  , ii develop a supervised machine learning technique for key concept identification and weighting  , and iii empirically demonstrate that our technique can significantly improve retrieval effectiveness for verbose queries. For information retrieval  , query prefetching typically assumes a probabilistic model  , e.g. Our model integrates information produced by some standard fusion method  , which relies on retrieval scores ranks of documents in the lists  , with that induced from clusters that are created from similar documents across the lists. In this section  , we analyze the probabilistic retrieval model based on the multinomial distribution to shed some light on the intuition of using the DCM distribution. With such a probabilistic model  , we can then select those segmentations with high probabilities and use them to construct models for information retrieval. Each model ranks candidates according to the probability of the candidate being an expert given the query topic  , but the models differ in how this is performed. We chose probabilistic structured queries PSQ as our CLIR baseline because among vector space techniques for CLIR it presently yields the best retrieval effectiveness. With the mapping probabilities estimated as described above  , the probabilistic retrieval model for semistructured data PRM-S can use these as weights for combining the scores from each field PQLw|fj into a document score  , as follows: Also  , PM Fj denotes the prior probability of field Fj mapped into any query term before observing collection statistics. He proposed to extract temporal expressions from news  , index news articles together with temporal expressions   , and retrieve future information composed of text and future dates by using a probabilistic model. In particular  , we hope to develop and test a model  , within the framework of the probabilistic theory of document retrieval  , which makes optimum use of within-document frequencies in searching. Progress towards this end  , both theoretical and experimental  , is described in this chapter. The language modeling approach to information retrieval represents queries and documents as probabilistic models 1. Researchers explicitly attempted to model word occurrences in relevant and nonrelevant classes of documents  , and used their models to classify the document into the more likely class. Similarly  , 16  integrated linkage weighting calculated from a citation graph into the content-based probabilistic weighting model to facilitate the publication retrieval. Using the notion of the context  , we can develop a probabilistic context-based retrieval model 2. For example  , for the query " bank of america online banking "   , {banking  , 0.001} are all valid segmentations  , where brackets   are used to indicate segment boundaries and the number at the end is the probability of that particular segmentation. The initial thresholds are set to a large multiple of the probability of selecting the query from a random document. The basic system we used for SK retrieval in TREC-8 is similar to that presented at TREC-7 11   , but the final system also contains several new devices. Figure 5shows the interpolated precision scores for the top 20 retrieved page images using 1-word queries. Assuming the metric is an accurate reflection of result quality for the given application  , our approach argues that optimizing the metric will guide the system towards desired results. Unlike most existing combination strategies   , ours makes use of some knowledge of the average performance of the constituent systems. There are two directions of information retrieval research that provide a theoretical foundation for our model: the now classic work on probabilistic models of relevance  , and the recent developments in language modeling techniques for IR. With respect to representations  , two research directions can be taken in order to relax the independence assumption 9  , 16. The use of these two weights is equivalent to the tf.idf model SALT83b ,CROF84 which is regarded as one of the best statistical search strategies. We calculate the log-odds ratio of the probabilities of relevant and irrelevant given a particular context and assign the value to the query term weight. Estimating £ ¤ § © in a typical retrieval environment is difficult because we have no training data: we are given a query  , a large collection of documents and no indication of which documents might be relevant. In the language modeling framework  , documents are modeled as the multinomial distributions capturing the word frequency occurrence within the documents. The language mod¾ However  , the motivation to extend the original probabilistic model 28 with within-document term frequency and document length normalisation was probably based on empirical observations. Our contributions are:  Presenting a novel probabilistic opinion retrieval model that is based on proximity between opinion lexicons and query terms. The standard probabilistic retrieval model uses three basic parameters  Swanson  , 1974  , 1975: In particular  , instead of considering only the overall frequency characteristics of the terms  , one is interested in the term-occurrence properties in both the relevant and the nonrelevant items with respect to some query. The probabilistic model described in the following may be considered to be a proposal for such a framework. In this study  , we further extend the previous utilizations of query logs to tackle the contextual retrieval problems. All these experiments have like ours  , been done on the CACM document collection and the dependencies derived from queries were then used in a probabilistic model for retrieval. In general  , our work indicates the potential value of " teaching to the test " —choosing  , as the objective function to be optimized in the probabilistic model  , the metric used to evaluate the information retrieval system. We have proposed a probabilistic model for combining the outputs of an arbitrary number of query retrieval systems. In this section  , we describe probFuse  , a probabilistic approach to data fusion. However  , to the best of our knowledge  , there have been no attempts to prefetch RDF data based on the structure of sequential related Sparql queries within and across query sessions. We created a half of the queries  , and collected the other half from empirical experiments and frequently asked questions in Java-related newsgroups. Relevance modeling 14 is a BRF approach to language modeling that uses the top ranked documents to construct a probabilistic model for performing the second retrieval. Being able to provide specific answers is only possible from models supporting LMU only conditionally  , as for example the vector space models with trained parameters or probabilistic models do 7. The central issue of statistical machine translation is to construct a probabilistic model between the spaces of two languages 4. In information retrieval  , many statistical methods 3 8 9 have been proposed for effectively finding the relationship between terms in the space of user queries and those in the space of documents. The probabilistic annotation model can handle multi-word queries while the direct retrieval approach is limited to 1 word queries at this time. Figure 4shows that this yields a much better ordering than the original probabilistic annotation  , even better than the direct retrieval model for high ranks. We first employ a probabilistic retrieval model to retrieve candidate questions based on their relevance scores to a review. In this paper we presented a robust probabilistic model for query by melody. Several probabilistic retrieval models for integrating term statistics with entity search using multiple levels of document context to improve the performance of chemical patent invalidity search. We have shown here that at least as far as the current state of the art with respect to Boolean operators is concerned  , a probabilistic theory of information retrieval can be equally beneficial in this regard. The classic probabilistic model of information retrieval the RSJ model 18 takes the query-oriented view or need-oriented view  , assuming a given information need and choosing the query representation in order to select relevant documents. This ranking function includes a probability called the term significunce weight that can estimated by nor- malizing the within document frequency for a term in a particular document. Representative examples include the Probabilistic Indexing model that studies how likely a query term is assigned to a relevant document 17  , the RSJ model that derives a scoring function on the basis of the log-ratio of probability of relevance 20  , to name just a few. To the best of our knowledge  , our paper presents the very first application of all three n-gram based topic models on Gigabyte collections  , and a novel way to integrate n-gram based topic models into the language modeling framework for information retrieval tasks. All Permission to copy without ~ee all or part o~ this material is granted provided th;ot the copyright notice a~ the "Organization o~ the 1~86-ACM Con~erence an Research and Development in Information Retrieval~ and the title o~ the publication and it~ date appear. In the next section  , we address these concerns by taking a more principled approach to set-based information retrieval via maximum a posteriori probabilistic inference in a latent variable graphical model of marginal relevance PLMMR. ln the experiments reported in this paper we have also incremented document scores by some factor but the differences between our experiment and Croft's work are the methods used for identifying dependencies from queries  , and the fact that syntactic information from document texts sentence a.nd phrase boundaries is used in our work. While the inherent benefits of longer training times and better model estimates are now fairly well understood  , it has one additional advantage over query centric retrieval that does not appear to be widely appreciated. These methods should be considered with respect to their applicability in the field of information retrieval  , especially those that are based on a probabilistic model: they have a well-founded thm retical background and can be shown to be optimum with respect to certain reasonable restrictions. To copy otherwise  , to republish  , to post on servers or to redistribute to lists  , requires prior specific permission and/or a fee. Despite this progress in the development of formal retrieval models  , good empirical performance rarely comes directly from a theoretically well-motivated model; rather  , Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. The way this information can be used is best described using the probabilistic model of retrieval  , although the same information has been used effectively in systems based on the vector space model Salton and McGill  , 1983; Salton  , 1986; Fagan  , 1987  , 1981  , 1983. For systems with great variability in the lengths of its documents   , it would be more realistic to assume that for fixed j  , X is proportional to the length of document k. Assumption b seems to hold  , but sometimes the documents are ordered by topics  , and then adjacent documents often treat the same subject  , so that X and X~ may be positively correlated if Ik -gl is small. Our goal in the design of the PIA model and system was to allow a maximum freedom in the formulation and combination of predicates while still preserving a minimum semantic consensus necessary to build a meaningful user interface  , an eaecient query evaluator  , user proaele manager  , persistence manager etc.