To evaluate the system performance    , we run the TPC-W on four architectures as illustrated in 
.In particular    , we experiment LogBase with TPC-W benchmark which models a webshop application workload.One transaction relates to exactly one action defined by the TPC-W benchmark.On FriendFeed users can comment and start discussions on the aggregated content    , similar to functionalities provided by typical OSNs.The TPC-W benchmark implements a fixed number of emulated browsers EBs that send requests to the system.Blog search engines such as Technorati have introduced new features enabling people to find authoritative feeds on a given topic.Heavy Queries vs. Light Queries
 Next    , we analyzed the performance of the three test systems under two very different queries of the TPC-W benchmark.The TPC-W metric for throughput is Web Interactions Per Second WIPS.We created a subset of the Newsvine dataset that includes only users with at least one friend and stories commented by such users    , etc.This paper studies the FriendFeed service    , with emphasis on social aggregation properties and user activity patterns.We constructed 20 training topics from BlogPulse http://www.blogpulse.com/ and Technorati search http://www.technorati.com/ archives and manually evaluated the search results of the training topics to generate the training data set of 700 blogs.WWW 
Scalability of the entire TPC-W
 We conclude this performance evaluation by comparing the throughput scalability of the OTW    , DTW and STW implementations of TPC-W.With 12 primaries    , ConfluxDB can produce almost 12 times the throughput of a single primary for the TPC-W workload.Evaluation
To evaluate TagAssist    , we used data provided to use by Technorati    , a leading authority in blog search and aggregation.For TPC-W queries    , this log merging delay was about 25% of the total latency.In addition to the evaluation of individual detection strategies     , we applied PPD to a 3rd party implementation of the well established TPC-W benchmark.Experimental Environment
The TPC-W benchmark models an online bookstore.We run most of experiments with TPC-W benchmark dataset 2 .Given the data types of the TPC-W benchmark    , we categorized these data types as shown in 
Costs.In Section 8    , we summarize the results of our experiments using the TPC-W and SCADr benchmarks.In our experiments    , we concentrate on the query execution part of TPC-W.CONCLUSION
 In this paper    , we report the observations made from popular queries published by Technorati over one year period.Furthermore    , the Newsvine friendship relations are publicly crawlable.The first dataset was crawled from the Newsvine news site 1 .Social Data
 As mentioned in Section 4    , the Newsvine site has a dedicated social network among its users.System under Test 
The TPC-W Benchmark 
Web 
B.We have chosen to crawl the Newsvine site    , among dozens of other available news sites    , since: 1 Newsvine is relatively easy to crawl due to the static HTML nature of its content pages; and 2 its registered users constitute a social network that is publicly visible.We implemented the full TPC-W workload in SharedDB.Results for TPC-W and for MySQL can be found in Appendix B.Note that FriendFeed being an aggregation service enables us to study different services from one common observation point    , and allows us to get a unique " sneak peek " on how these social networking and content sharing services are being used by a common set of users.TPC-W 10 : The TPC-W benchmark from the Transaction Processing Council 
Evaluation Platform
We run our Web based applications on a dynamic content infrastructure consisting of the Apache web server    , the PHP application server and the MySQL/InnoDB version 5.0.24 database storage engine.In TPC-W    , one server alone can sustain up to 50 EBs.TPC-W defines three transaction mixes: browsing    , shopping    , and ordering mixes.  , BlogPulse and Technorati.The database defined by the TPC-W benchmark contains 8 different data types e.g.In the case of SRAA dataset we inferred 8 topics on the training data and labeled these 8 topics for all the three classification tasks discussed above.Some exceptions exist    , like BibSonomy 1 bookmarks + bibtex    , sevenload 2 pictures + video    , or technorati 3 blogs + video.In order to test this    , we collected articles from Technorati and compared them at a syntactic level.The TPC-W benchmark models a Web shop    , linking back to our first use case in Section 2.TPC-W contains a total of 14 different web interactions.In fact    , it is as hard as finding the optimal joining plan 
SUMMARY OF THE METHODOLOGY
EXPERIMENTS
 We have carried out experiments on MyBenchmark using workloads from TPC-W and TPC-C benchmarks.  , Technorati Top 100 Blogs    , The Bloggies Annual Weblog Awards    , The Edublog Awards    , TIME The Best Blogs    , and Bloggeries Blog Directory.We then run TPC-W and TPC-C queries on 2 primaries so that every global transaction will involve every primary.The TPC-W workload consists of 11 web-interactions    , each consisting of several prepared statements    , which are issued based on the frequencies defined by the TPC-W browsing mix.OutLinks Acting on the observation that personal blogs often have link to sites of interest to the blogger    , we also obtain the number of outgoing links of a blog using the Technorati Cosmos API.We use what is effectively the current standard workload generator for e-commerce sites    , TPC-W 
Client Workload Generator
 The Rice TPC-W implementation includes a workload generator     , which is a standard closed-loop session-oriented client emulator .TPC-W Query Execution
We scale TPC-W by first bulk loading 75 Emulated Browsers' worth of user data for each storage node in the cluster.Finally    , we note that it appears that less active users are less likely to join an aggregation service such as FriendFeed.For example    , Technorati 1 lists most frequently searched keywords and tags.We evaluate our Pyxis implementation on two popular transaction processing benchmarks    , TPC-C and TPC-W    , and compare the performance of our partitions to the original program and versions using manually created stored procedures.In Section IV    , we apply PPD to the TPC-W benchmark in two different deployment environments.YCSB+T transactional NoSQL benchmark
 Traditional database benchmarks like the TPC-W are designed to measure the transactional performance of RDBMS implementations against an application domain.We use TPC-W benchmark    , which simulates a bookstore Web site.Furthermore    , the TPC-W benchmark states that all database transactions require strong consistency guarantees.The news site Newsvine uses a similar concept     , where a user's " vine " image represents their history and tenure with the site.Technorati provided us a slice of their data from a sixteen day period in late 2006.ADDITIONAL EXPERIMENTAL RE- SULTS 
B.1 Overhead During Normal Operation 
 In this experiment    , we measure the overhead during normal operation for the TPC-C benchmark running on MySQL and the TPC- W benchmark running on Postgres.SEARCHING FOR PERFORMANCE PROBLEMS IN THE TPC-W BENCHMARK We use the TPC-W Benchmark 
A.These application servers carried out transactions following the Ordering mix defined by the TPC-W benchmark.Our experiments are based on the TPC-W benchmark 
Experimental setup
TPC-W benchmark.In general    , since response times for TPC-C update transactions are lower than TPC-W update transactions    , our expectations that the log merging delay will also be lower as the timespan of the TPC-W transactions is longer is confirmed.Experimentally     , we determined from 1P results that having between 400 to 800 clients for TPC-C and 250 to 500 clients for TPC-W generates load without underloading or overloading the primaries.Please consult 
Characterization Results 
Network Properties 
Subscription to Services and Aggregation 
This section dives into the social aggregation properties of FriendFeed.Execution Strategies
We also evaluate the effect of different execution strategies on the TPC-W queries' response time.For SRAA dataset we learnt 10 topics on the complete dataset and labeled these 10 topics for all the three classification tasks.At the same time    , 
SCADr
We scale SCADr using a methodology similar to the TPC-W benchmark by varying the number of storage nodes and clients.FriendFeed www.friendfeed.com is one such service.TPC-W benchmark models the workload of a database application where OLTP queries are common.For SRAA dataset we infer 8 topics on the training dataset and label these 8 topics for all the three classification tasks.In the following    , we argue that it is not and motivate an alternative metric for blog post credibility that we are currently prototyping in a blog search and analytics engine for news blogs on foreign relations see 
Credibility vs. authority
The Technorati 1 blog search engine calculates a measure of blog authority as the log of the number of incoming blog links over a six month period 
Measuring credibility
We are constructing a measure of blog credibility that takes into account source    , message and reception features of bloggers.For example     , TPC-W 
Conclusions
We have presented a text database benchmark and a detailed synthetic text generator that can scale up a given collection of documents.FriendFeed allows users either to filter by people or to use a form-based search tool 1 .InLinks We assume that non-personal blogs are more likely to have a large number of incoming links than personal ones    , and use the Technorati Cosmos API 2 to obtain this number.TPC-W defines three different workload mixes: Browsing    , Shopping    , and Ordering.gorizing all data types as A data complies with the requirements of the TPC-W benchmark.Other tables are scaled according to the TPC-W requirements.Our second testbed is a deployment of the TPC-W benchmark 7     , with the following details.Analysis of Individual Web Interactions
 The TPC-W benchmark involves a variety of different web interactions     , each involving a different set of queries.Because read-only transactions do not produce this overhead at all    , the higher the ratio of update transactions become    , the bigger overhead LRM suffers 
TPC-W Benchmark
The TPC-W benchmark 
Experimental Setup
We use up to 7 replicas    , one is the leader master and the others are followers slaves for database node.The prepared statements were issued based on the frequencies defined by the TPC-W Browsing mix.A friend on FriendFeed is a unidirectional relationship.ConfluxDB relies on the update transactions in the workloads in particular    , TPC-C and TPC-W used for our experiments to touch only rows with a particular key e.g.Commenting on aggregated content facilitates information dissemination in the FriendFeed network.1. sim auto vs sim aviation vs real auto vs real aviation 2. auto sim auto + real auto vs aviation sim aviation + real aviation 3. simulated sim auto + sim aviation vs real real auto + real aviation We randomly split SRAA dataset such that 80% is used as training data and remaining is used as test data.The TPC-W benchmark measures the request throughput by means of emulated browsers EBs.A FriendFeed user can choose to aggregate content from among the supported services into the user's FriendFeed profile page.As with TPC-W    , all data is replicated on two servers for increased availability.In the distributed TPC-W system    , we use this object to manage catalog information    , which contains book descriptions    , book prices    , and book photos.The average latencies were then measured during each 30-second period     , as shown in 
TPC-W
In the next set of experiments    , we used a TPC-W implementation written in Java.We selected 500 of the articles collected from Technorati and    , for each of these articles    , we extracted the three words with the top TFIDF score.For example    , the TPC-W workload has only 14 interactions     , each of which is embodied by a single servlet.We are also interested in understanding the characteristics of the FriendFeed social network and how they relate to the characteristics of the social network services that it aggregates.The amount of data and the length of the experiment are kept the same as in the TPC- W scale experiment described in the previous section.In this section we discuss the design and evaluation of the key distributed objects in the distributed TPC-W system.Then using FriendFeed 5 data    , we identified users who also have FriendFeed accounts.The replay time    , which is the time taken to transactionally apply the log record using the unmodified PostgreSQL hot standby feature constituted about 70% of the total latency for TPC-W queries while it is about 80% for TPC-C.The first phase captured the network of FriendFeed users    , while the second phase captured the activity of the users identified in the first phase over a period of five weeks.Technorati.WWW2003    , 
TPC-W BACKGROUND
 TPC Benchmark W TPC-W is an industry-standard transactional web benchmark that models an online bookstore 
SYSTEM DESIGN
Overall architecture
As 
Design Principles
Design trade-offs for our distributed TPC-W system are guided by our project goal of providing high availability and good performance for e-commerce edge services as well as by technology trends.FriendFeed allows aggregation of information from a number of services that include popular social networking     , video sharing    , photo sharing    , and blogging services.First we present experimental results to validate the correctness of the two heuristics of our algorithm and then we present results on the generated plans of two well known workloads     , the TPC-W and the TPC-H benchmarks.Some services incur either 271 
WWW 
Scaling the financial service of TPC-W
The denormalized TPC-W contains one update-intensive service: the Financial service.A FriendFeed user can " follow " the activity of other users of this service by subscribing them as " friends " .In this paper    , we first give an overview of the popular queries collected from Technorati http://www.technorati.com/    , a well-known blog search engine    , over one year period.Technorati also provides a RESTful 
USES OF TAGS
We are particularly interested in determining what uses tags have.The SRAA corpus contains 73  ,218 UseNet articles from four discussion groups: simulated auto racing    , simulated aviation    , real autos    , and real aviation.  , using statistical natural language processing and/or by relying on white-lists provided by vigilante groups    , such as Technorati.We present here performance evaluations of TPC-W    , which we consider as the most challenging of the three applications.TPC-W defines three workload mixes    , each with a different concentration of writes.We use two workloads    , TPC-W and TPC-C    , in our experiments.Settings for the Experiments
Our simulator and TPC-W testbeds 
 We conducted experiments on two testbeds    , both implemented in Java.Under this access pattern    , the system load distribution is highly skewed as shown in 
C.3 TPC-W Benchmark 
We now describe the results when testing ecStore on EC2 with TPC-W benchmark    , which models the on-line book store application workload.We began by collecting the 350 most popular tags from Technorati .The experimental results with the TPC-W benchmark showed that the overhead of Pangea was very small.First    , PPD identified a One Lane Bridge OLB in the TPC-W application deployed in Setup A.Thus    , we ran experiments to measure this log merging delay using TPC-C and TPC-W queries.According to a recent survey made by Technorati 
RCS ARCHITECTURE
INCREMENTAL STORY CLUSTERING
Note the daily crawled data could be treated as a data stream.