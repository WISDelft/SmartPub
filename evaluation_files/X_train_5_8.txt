For City Youngstown  , OH  , its Wikitravel page is " 2. The ratings over the examples are distributed more evenly  , with the lowest rated example having an average rating of 1.41 and the highest 3.49. For this context  , the Model- Anchor retrieves the disambiguation page of the wikitravel for Clarksville cities. Xanga treats email addresses differently: users can provide their email address to Xanga  , and visitors can use the website to send email  , without the address being visible directly. The crawled and concatenated text of each of the 5 Wikitravel categories served as document representations  , which we indexed using Indri. The article contains 24 ,298 words  , received 5 ,834 in-links and provided 92 ,379 out-clicks. We extracted site-internal links from all the States  , Regions  , Cities  , Districts and Burroughs sections. Then  , we discuss our first two approaches  , which are relatively straightforward and mainly used for comparison: the random ranking of destinations Section 2.2  , and the list of the most popular destinations Section 2.3. As a matter of fact  , there are based on the only anchor text of the pages in the tiny aggregators sub collection. In this section we will describe our experimental setup and evaluation approach  , and the results of the experiments. This paper reports on large-scale experiments with four different approaches to rank travel destination recommendations at Booking.com  , a major online travel agent. The Do and Drink categories are the least liked while the Eat category is the highest rated. We collected all the reviews for some hotels in these sites. We focused on a service called destination finder where users can search for suitable destination based on preferred activities. The data was parsed and used to construct a graph  , where each node corresponds to a blog user and a directed edge between two nodes corresponds to a blog entry of one of the users having a link to the other user's blog or entry therein. A set of labels in the ensemble decision are then substituted based on a local genre hierarchy  , represented as a taxonomy. In our study  , we use more than 15M reviews from more than 3.5M users spanning three prominent travel sites  , Tripadvisor   , Hotels.com  , Booking.com spanning five years for each site. In this section  , we present our ranking approaches for recommendations of travel destinations. To create the seed set for Xanga we took advantage of the concept of " metros " : each metro corresponds to a geographical region in which users locate themselves. We also see a noticeably high number of potentially duplicated profiles across sites  , sometimes due to setting up multiple blogs one for family  , one for friends  , perhaps due to wanting to " start over " afresh. In summary  , our experiments show a surprising willingness of users to make their private contact information available. Styles do not perform as well as genres H@3 of 0.76  , mostly due to the fact that the AllMusic labels are too fine-grained to clearly distinguish between them 109 classes. This is most common on Xanga which has the youngest users. There are big differences in the overall score of a hotel across different sites. Finally we calculate the cosine similarity score 2 between the extracted phrase p and each retrieval document's title t j   , and keep the document with the highest score as the Wikitravel page for that city. If suggestions from outside the context cities are geographically irrelevant  , we should focus on finding other sources for suggestions in those cities where few are provided on Wikitravel. We first discuss our baseline  , which is the current production system of the destination finder at Booking.com. Over half of Xanga users list some URL under the Webpage category; however on closer examination the URLs listed we saw that a large number do not refer to personal webpages but rather to popular or favorite websites   , e.g. In the bottom half of Table 2we show rating statistics per Wikitravel category  , based on the estimated category per example. As illustrated in Figure 3  , a similar pattern is observed for the evaluation by the TBG metric. By estimating the Wikitravel category for the provided examples  , we created personalised category prior probabilities. Hotels show various inconsistencies within and across hosting sites. The dataset integration and data preparation is done in two steps. Bloggers that provide music codes to add to blogs which play music and video are also popular in Xanga XaNgA MuSiC  , Music Galore. Using a tf-idf measure  , we extracted the top 30 keywords for each example website  , that could serve as queries. for the articles " AllMusic "   , an online music database  , and " Billboard magazine " are notable: Even though both articles are music-related  , they lack a direct connection to Elvis Presley. Therefore   , we use the descriptions from the 50 examples and the 21 ,872 Wikitravel suggestions to assign the 50 examples to the 5 Wikitravel categories. This systems extracts suggestions for sightseeing  , shopping  , eating  , and drinking from Wikitravel pages dedicated to US cities. This paper investigates strategies to recommended travel destinations for users who provided a list of preferred activities at Booking.com  , a major online travel agent. Descriptions from positive examples in the user profiles are used as queries to rank suggestions. A metro has anywhere from a single user to hundreds of thousands of users listed within it. Issuing the generated queries based on the top 30 keywords per site resulted in a ranked list of the 5 candidate categories for each given example website. We crawled all Wikitravel pages of locations within the US  , starting with the page on the United States of America as the seed list. Devaluating or ignoring these links in future studies should improve the performance of the link-based similarity measures. These recommendations were caused by links that did not belong to the actual article text  , e.g. 'London'  , provides the review riuj  , d k  as: riuj  , d k  = 0  , 1  , 0. We extracted a larger number of suggestions from Wikitravel pages on cities and towns in the US and created two systems that generate geographically independent rankings. Is there a relation between the number of suggestions available in the context city and the number of suggestions that are geographically relevant ? In the reminder of the paper  , we will use HDC for Hotels .com  , TA for TripAdvisor.com and BDC for Booking.com. We consider the difference between the baseline and the newly proposed method significant when the G-test pvalue is larger than90%. We focus on location disambiguation problem across these three websites. Second  , the reason of the difference between the average M RR of Model-Anchor and Model-Text for the profile 700 is his/her judgment in " Kalamazoo MI " context. For each section  , first we extract all bold phrases. f Xanga web-link categories In this section we study the prevalence with which this information is available  , and use this information to understand the extent to which one user may create multiple blogs. The top blogs on Xanga from our data include blogs of celebrities  , mostly from Hong Kong MandyStarz  , kellyjackie and stephy tang. One system also ignores individual user preferences  , while the other tries to take those preferences into account when ranking suggestions. Figure 1depicts a small portion of the local genre hierarchy. In order to generate user profiles the ratings users gave for the example attractions along with the created vectors that represent each sample attractions are combined and passed to the Softmax algorithm. We provide True- View as a proof of concept that a cross-site analysis can significantly improve the information that the user sees. This year we experimented with the Wikitravel suggestion categories for buying  , doing  , drinking  , eating and seeing. To assign the examples to the categories  , we crawled all 50 example websites  , downloading the homepage from each example  , and following site-internal links up to one level deep. Thus  , although over a sixth of Xanga users have provided email addresses  , we cannot use it when trying to match users across networks. We use similar configuration to index the Wikitravel dataset. We find that 10.4% of common hotels from Booking.com and TripAdvisor.com  , 9.3% from Hotels.com and TripAdvisor.com  , exhibit significantly different rating characteristics  , which is usually a sign of suspicious behavior. These ranked suggestions are then filtered based on the context. For our experiments  , we derive our local genre hierarchy based on the taxonomy of music genres developed by Allmusic 1 . First  , we will detail our online evaluation approach and used evaluation measures. We crawled TripAdvisor.com  , Hotels.com  , and Booking.com. These are provided by a community of travellers and locals and can be used as a source for contextual sugges- tions. The resulting test collection can be used to evaluate destination and venue recommendation approaches. We take advantage of a production A/B testing environment at Booking.com  , which performs randomized controlled trials for the purpose of inferring causality. 848 hotels were matched across all three sites  , 1007 between Booking.com and Hotels.com  , 655 between Booking.com and TripAdvisor.com  , and 10 ,590 between Hotels.com and TripAdvisor.com. For example  , in the article on Elvis Presley  , CoCit identified the link to the " AllMusic " category at the top rank. For the baseline system  , suggestions are ranked per user profile based on their positively rated examples and filtered on the geographic context. The striking differences in the nature of what is most popular on each blogging server gives a sense of the community of the users on each. Due to the fact that the Nashville is just 47.8 miles further than the Clarksville in the state of Tennessee  , this page is judged as a relevant suggestion. Wikitravel Page = the i th document  , where Table 2The "See" section of document "Houma travel guide -Wikitravel" After retrieving one city's Wikitravel homepage  , we examine the " See "   , " Do "   , " Eat "   , " Drink " and " Buy " sections in that page  , and extract famous venues from these sections. Figure5f illustrates that the percentage of users that share any IM contact decreases with age. It is evident that Moussaoui is talked about more by Blog Spot users than Live Journal or Xanga  , even though it has only a third of Live Journal's authors. works  , while Blogger users are the most discrete among the three networks: none of the examined Blogger users had listed and made visible their email address under the Email category. However  , the Clarksville is not mentioned in the anchor text of the Nashville wikitravel page  , and it is reasonable that it is not included in the top-5 ranking of the Model-Anchor. The output of this technique RunA is compared with using KNN instead of the Softmax algorithm RunB. Xanga. In Table 6 we see the distribution of Wikitravel categories over the top 5 retrieved suggestions and over all suggestions in the index.