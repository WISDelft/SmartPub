The official evaluation results of JNLPBA 4 and BioCreative 2004 5 show that the state-of-the-art performances are between 70%-85% varying with different evaluation measures. Table 3shows the performance of our model compared to the top four models in the SemEval 2015 competition note that only the F1-score is reported by SemEval for this task and ParagraphVec. The results show that our proposed approach outperforms all the systems in the JNLPBA shared task. For evaluation we use the official scorers from Semeval 2015  , which compute the average between F-measures for the positive and negative classes. After that  , we design the experiments on the SemEval 2013 and 2014 data sets. Covering these cases enables us to model queries over such data and analyze the effects of executing such queries. Even though there are three classes  , the SemEval task is a binary task. For computational efficiency reasons  , we learn recency weights over the previous 200 positions only. Therefore the queries are relatively long and the writing quality is good. In particular  , and as will be discussed in detail in Section 3  , we use keyword extraction in a subroutine to efficiently find a small subset of diverse keyqueries. Recency is clearly present in MAPCLICKS and BRIGHTKITE  , and absent from SHAKESPEARE and YES. NER in biomedical domain has attracted the attention of numerous researchers in resent years. We also compute a separate baseline to account for the most heavily consumed items: we calculate and report the fraction of hits when the cache is fixed to always contain the top k most frequently consumed items. When we compare the SEG module recall 80.45% with the results reported in the JNLPBA shared task in Table 3   , it is clear that subsequent good classification results will yield a good overall F 1 . The results show our advanced Skipgram model is promising and superior. For BRIGHTKITE  , PDP captures essentially all of the likelihood. Although different results are obtained for SEMEVAL and ODP- 239  , steady results are obtained for WEBSRC401 by the Dual C- Means configured with the S T S word-word similarity metric. Overall  , these results are encouraging and preliminary at the same time. For privacy reasons  , we only consider pages clicked on by at least 50 distinct users  , and only consider users with at least 100 clicks. Another example is the LinkedGeoData project 4 which provides Linked Data about any circular and rectangular area on Earth 4. Deep analysis shows that ARI embodies an interesting property for the SRC task as it is well-known that the sizes of the clusters are not distributed equally on the Web. Using large language model with and word co-occurrences  , we achieve a performance comparable to the systems in SemEval 2013  , task 13 23. We now describe the parameter setting used for the model. For each mention  , the entity linker provides a distribution over the top fifty most probable entities.