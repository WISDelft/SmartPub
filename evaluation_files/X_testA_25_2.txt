All experiments were performed on a 1GHz Pentium III processor with 1GB RAM running Linux kernel 2.4. Those are mutually exclusive with testing data in Genome Task and our testing data. We made several approaches to ensure that we visited a large and representative section of the open Semantic Web. The TWSI dataset is mostly used for parameter tuning and determining the best feature configuration. In AlgoViz we used the results in two ways: 1 within the content recommendation block that suggests a list of entries based on the DSN analysis results and 2 within the ranking function that generates the ordered list of entries for users during browse and search operations. The number of sampling iterations for the topic model of each month was 200. We report the results for training the network on the official supervised dataset from Semeval'15 using parameters that were initialized: i completely at random Random; ii using word embeddings from the neural language model trained on a large unsupervised dataset Unsup with the word2vec tool and iii initializing all the parameters of our model with the parameters of the network that uses the word embeddings from the previous step and are further tuned on a distant supervised dataset Distant. Experimental results over Blog06 collection showed the advantage of using multiple opinion query positions in comparing the opinion score of documents. However  , this information is not directly available in the publicly available data dumps provide by Stack Overflow . OWA operator was used as an aggregator in our system. Traditional benchmark databases  , such as Wieconein and AS3AP  , are primarily geared toward8 performance assessment of the algorithm8 in relation to the architecture . The Disk4&5 collection contains newswire articles from various sources  , such as Association Press AP  , Wall Street Journal WSJ  , Financial Times FT  , etc. The remainder of this paper is structured as follows. While it is public knowledge that Quora differs from its competitors in its use of social networks and real identities  , few additional details or quantitative measures are known about its operations. rdfs:subClassOf  , owl:SubObjectPropertyOf. The model takes into account a user's page viewing history  , page viewing trends captured using DSNs  , and text similarity between page titles. Finally  , we look at Peetz et al's classification of the Blog06- 08 topics 850-1050. These services host large numbers of collections  , focused on subjects as diverse as geographical information  , sports  , technology   , science  , TV shows  , fiction  , events  , and books  , to cite only a few. A simple search on Quora about how it works produces numerous unanswered questions about Quora's size  , mechanisms  , algorithms  , and user behavior. We imported the Shapefiles into a PostGIS database and created virtual geospatial RDF views on top of them using Ontop-spatial  , as described at https://github. Empirically measuring the quality of recommendations has  , in the past  , fallen into two camps. Experiments on the KDDCUP 2005 data set show that the bridging classifier approach is promising. After 20 opinions were collected the next button terminated the study. This dataset  , from the German movie-rental site MoviePilot  , was released as part of the We overcome this by using a dataset that contains individual user preferences and their group membership. Not all nodes in this Semantic Web graph are entities; identifying the nodes which refer to an entity is one of the challenges introduced by the task. From the Wikia service  , we selected the encyclopedias Wookieepedia  , about the Star Wars universe  , and Muppet  , about the TV series " The Muppet Show " . Using large language model with and word co-occurrences  , we achieve a performance comparable to the systems in SemEval 2013  , task 13 23. trigram or dependency features. For evaluation we use the official scorers from Semeval 2015  , which compute the average between F-measures for the positive and negative classes. In BlogPulse  , according to the splog detection methodology presented in 14  , the percentage of splogs is 7.48%. The dataset for the ELC task is the Billion Triple Challenge dataset 2 . Although different results are obtained for SEMEVAL and ODP- 239  , steady results are obtained for WEBSRC401 by the Dual C- Means configured with the S T S word-word similarity metric. It turned out that ruling out terms Figure 1 : MAP and P@10 for short queries at different pruning levels  , baseline and different settings WT2g collection   , as those terms have a negative score for every document. Furthermore  , the retrieval of relevant websites is based on Automatic Query Generation 12   , i.e. In particular  , OpenStreetMap OSM is an initiative for crowdsourcing map information from users. We conclude that considering the meta data available on Stack Overflow along with natural language characteristics can improve existing approaches when applied to Stack Overflow data. Thus  , for more effective retrieval  , we looked at ways to expand our query. We used the combined information in LocusLink and MEDLINE to identify the descriptors used to characterize the organisms for MEDLINE documents. WebKB 27  uses conceptual graphs for representing the semantic content of Web documents. Some prolific developers are even considered "coding rockstars" by the overall community 5. WebKB This dataset contains webpages from computer science departments at around four different universities 7 . Another problem is  , although less frequent  , that the extracted URLs are sometimes not permalinks but hyperlinks to the web pages the blog posts are commenting on. To examine as many different implementations and hosts as possible  , we noted that the Billion Triple Challenge 2014 13 dataset consisted of a 4 GTriple corpus of spidered Web data. First a connectivity server was made available on the Web. Therefore   , it is fair to compare them on these four collections. Downvotes are processed and only contribute to determining the order answers appear in. 2 Each query produced a set of documents corresponding to a LocusLink organism. We started by identifying all the distinct hosts represented in the 100 gigabyte collection. The largest data sets is composed of a portion of pages referenced from ODP directory at http://dmoz.org. In this section  , we introduce Quora  , using Stack Overflow as a basis for comparison. 3 For client-side projects  , we select from the most popular JavaScript projects on GitHub. The implicitly held assumption Assumption 1 may not always be true for data streams. In this paper  , we perform a detailed measurement study of Quora  , and use our analyses to shed light on how its internal structures contribute to its success. This paper proposed automatic approaches to extract gene function in the literature. The overall architecture of the extraction from Medline to candidate GeneRIF is shown in Figure 2. We also recall that questions on Stack Overflow are not digitally deleted i.e. A text classifier similar to that used in 2 is applied to classify each Web document in D into predefined categories in KDDCUP 2005. To answer our research questions  , we created and analyzed a dataset from the social open source software hosting site GitHub 12. Given the rapid growth of questions on question-and-answer sites  , how does Quora help users find the most interesting and valuable questions and avoid spammy or low-value questions ? We conducted two studies to evaluate CodeTube. The Stack Overflow ! In Section 5  , we compare the approaches empirically on the tasks of KDDCUP 2005 competition. The third data set was collected by the WebKB Project 4. We also introduced an algorithm using the collection's information in prior art task for keyword selection. 3how to deal with long queries in Prior Art PA task ? All reported data points are averages over the four cluster nodes.  We evaluate Section 4 the probabilistic model alongside state-of-the-art CF approaches  , including popularity based  , neighbourhood  , and latent factor models using household rating data from MoviePilot 1 . The detail of our data preparation can be found in Section 6. Fig- ure 16shows the word cloud of the top-50 tags that occur in undeleted questions on Stack Overflow. We observe similar trends in Quora. Thus in our analysis of Quora  , we only refer to upvotes and disregard downvotes .  offTopic: contains terms related to the query but unlikely to occur within relevant documents. To answer that  , we first need to understand more about what the web looks like. All of them are available online but distributed throughout the Web. These users are referred to as Anonymous users and have a default user ID of 0. We created a HIN by categorizing the entities into vertex labels: author  , paper  , conference  , and terminology. In order to empirically estimate the magic barrier  , a user study on the real-life commercial movie recommendation community moviepilot 4 was performed. OpenStreetMap OSM maintains a global editable map that depends on users to provide the information needed for its improvement and evolution. Experiments are performed on Web data taken from the Billion Triple Challenge and the Web Data Commons datasets. To answer our research questions  , we followed a mixedmethods approach characterized by a sequential explanatory strategy 15. Naturally  , there may be considerable variation from one topic to another. Even though it was not utilized to produce official runs  , Figure 4presents a digest of the extraction algorithm for completeness. By obtaining evidence that our samples are faithful  , we avoid processing large Web crawls  , although even our sampling experiments have fetched almost 16 million pages. See Figure 4for an example of the results generated by a query "Vegetable Soup Recipes". About 300 training documents were available per topic. A similar rationale extends to the other intrusions with low detection rates. We recall that experienced community members viz. A new collection  , called Blog06  , was created by the University of Glasgow. The collection can be sorted by author  , title  , publication type  , or publication year. We also aim at improving the OpenStreetMap data usage scenario  , e.g. This further supports our hypothesis that Quora's social graph and question graph have been extremely effective at focusing user attention and input on a small subset of valuable questions. We even achieve superior performance for very short documents 6â€“8 words in the SemEval task as long as we can link to at least one entity. A query-biased snippet is one selectively extracted on the basis of its relation to the searcher's query. By performing all knowledge graphrelated work in the Semantic Document Expansion preprocessing step  , we also achieve a highly scalable solution. We computed Fleiss' Kappa to measure the inter-annotator agreement for this task  , obtaining 0.241 for the Quora topics   , 0.294 for the HF topics  , and 0.157 for the NYT topics. Once again  , it is clear that the group recommendation model based on the IMM outperforms the other two methods. Figure 3below shows the precision at 5 -1000 documents returned from running the modified queries on WT2g. Our analysis reveals interesting details about the operations of Quora. All figures are generated by our modified version of Java OpenStreetMap Editor 2 which is a map editor for OpenStreetMap 3 written in Java. The 17 ,958 splog feeds in the Blog06 collection generated 509 ,137 posts. For each video fragment   , we also show the top-three relevant Stack Overflow posts  , and ask RQ3 to what extent they are relevant and complementary to the video tutorial fragments. The naive approach would be to consider each GitHub repository as its own separate project. Since the Web content  , user interactions  , and networking are exactly the same for these browsers  , WPBench produces benchmark results fair to different Web browsers. Thus  , we decided that finding best sentences in the corresponding MEDLINE citations might serve the purpose of the secondary task. The vocabulary consists of 20000 most frequent words. The Blog06 test collection includes a crawl of feeds XML  , associated permalinks HTML  , retrieval units  , and homepages during Dec 2005 through early 2006. The application of opinion modules is similar to on-topic retrieval optimization in that opinion scores generated by modules act as opinion reranking factors to boost the ranks of opinionated blogs in the topic-reranked results. Algorithm 1 is very simple  , easy to implement and don't need any external biomedical resource. The difficulties include short and ambiguous queries and the lack of training data. We notice the presence of programming related tags like objective-c  , android and c# which points out these undeleted questions are relevant to Stack Overflow. We use a charity donation dataset KDDCup 1998 that chooses a subset of population to send campaign letters. 3. Our estimated number of questions in Quora for June 2012 is 700K  , which is consistent with previously reported estimates 24. The data consist of a set of 3 ,877 web pages from four computer science departments. It is based on a large and active community contributing both data and tools that facilitate the constant enrichment and enhancement of OSM maps. After deduplication   , there are about 886 million triples  , 175 million resources  , and 296 million literals. In the case of resources  , semantic similarity refers to the degree of relatedness between two Web sites or documents  , as perceived by human subjects. The publication of the OpenStreetMap data using Triplify adds a completely new dimension to the Data Web: spatial data can be retrieved and interlinked on an unprecedented level of granularity. Contrary  , in AOL the temporal component takes over. We sent an online survey to 851 GitHub users selected from the set of prolific developers described earlier. For WebKB  , we used a subset containing 4 ,199 documents and four categories. In this paper  , we describe an experiment using 300 randomly sampled websites from dmoz.org. We also perform a dataset analysis and develop a cost model that provide insight into why particular strategies are effective for Web Data. Since each Quora user lists the topics she follows in her profile  , we estimate the number of followers by examining user profiles in our crawled dataset. For example  , the 1998 KDDCUP dataset 4 contains only 5% positive data and 95% negative data. The last data set DS 5 consists of health care web sites taken from WebKB 3 . .  Stack Overflow is another successful Q&A site started in 2008. To facilitate the crowdsourcing of documentation  , the Stack Overflow community explicitly encourages contributions where the person asking the question also provides an answer. Apart from existing as a question-answering website  , the objective of Stack Overflow is to be a comprehensive knowledge base of programming topics. Our approach generally outperforms IG  , and the advantage becomes larger with the increase of data size. Upon selection of one sentence  , the sentence is expanded to show the surrounding paragraph from the original source  , along with a link to the corresponding Stack Overflow thread. Even though there are three classes  , the SemEval task is a binary task. As Quora and its repository of data continues to grow in size and mature  , our results suggest that these unique features will help Quora users continue find valuable and relevant content. , 45% of all collaborative projects used at least one pull request during their lifetime. We then transformed the dataset into "course" and "non-course" target values. Figure 10shows the venn diagram of tag distributions of questions on Stack Overflow. The assessors checked the number of relevant documents in the Web collection once they had a candidate topic from searching the ad hoc collection. The same problem was found for BLOG06-feed-000036  , BLOG06-feed-000043  , and many others. Finally  , empirical evaluation shows that TSA exhibits superior performance compared to the previous state of the art method ESA  , and achieves higher correlation with human judgments on both datasets. on dmoz.org most of them focus on the generation of references to include in own publications. Table 8shows the results of all of the single-pass retrieval methods on three collections. KIM 2 provides a novel Knowledge and Information Management infrastructure and services for automatic semantic annotation  , indexing  , and retrieval of documents. At the end of 2012  , GitHub hosted over 4.6M repositories. When we use only similarity between the page titles to build the model  , the recommendation framework does not perform well. To describe the differences of the data models that express the same example instance with different vocabularies and vocabulary terms  , we make use of features such as the number of datasets using a vocabulary or the total occurrence of a vocabulary term. We used Github APIs to search 3 for SW repositories and to collect contact information for the corresponding contributors when available. Up to August 2013  , 1.9 million pull requests from more than two hundred thousand projects have been collected. Our approach was based on using the WT2g dataset  , consisting of 247 ,491 HTML documents at 2GB storage requirements. Threats due to sampling bias: To ensure representativeness of our samples  , we opted to use search results from the Github repository of Java projects that use the Maven build system. The sessions are the nodes and an edge between two sessions indicate they share k common pages. Thus  , we aimed at augmenting folksonomy-style tagging by more standard ways of assigning metadata. However  , it was not clear to us if these fields are of sufficiently high quality and how exactly we could make good use of them. 6 Table 2summarizes the most popular point-of-interest annotations currently found in the OpenStreetMap data. separating the wheat from the chaff  , is a very difficult problem. The study showed that sentences extracted by SISE were considered significantly more meaningful and resulted in the most sentences that added useful information not contained in the API documentation. In our dataset  , most pull requests 84.73% are eventually merged. In the end  , only 15.0% 54/360 of the factoid questions had an answer that could be found only in the Blog06 corpus; 24.8% 235/946 of the distinct items answering a list question could be found only in the Blog06 corpus; and at most 6.1% 45/735 of the distinct nuggets answering an Other question could be found only in the Blog06 corpus. We assigned topical labels to extracted URLs to identify which were medically related. This enhancement enables a variety of new Linked Data applications such as geo data syndication or semantic-spatial searches. This dataset  , from the German movie-rental site MoviePilot  , was released as part of the There are about 8280 documents and they are divided into 7 categories: student  , faculty  , staff  , course  , project  , department and other. The goal of LinkedGeoData is to add a spatial dimension to the Semantic Web. Web page classifiers based on SVM algorithm are trained beforehand for a few topics of DMOZ http://dmoz.org. There are a total of 37 solutions from 32 teams attending the competition. This is the focus of the rest of our paper  , where we will study different Quora mechanisms to understand which  , if any  , can keep the site useful by consistently guiding users to valuable information. In the uniques relation all attributes have unique values. Further  , the network representation could be expanded to include editor interaction on the Talk pages  , which might reveal collaborative sequences such as Talk page discussion followed by article revision. , products  , organizations  , locations  , etc. Bio2RDF dataset vocabularies and their SIO-mappings are stored in separate OWL ontologies on the bio2rdf-mapping GitHub repository 8 . The advantage of using the Stack Overflow API over the Stack Overflow data dump used in previous research such as that of Bacchelli et al. Figure 1illustrates the distribution of feed sizes in the corpus. There are about 8 ,300 documents and they are divided into seven categories: student   , faculty  , staff  , course  , project  , department and other. Next  , we rank the topics by the number of followers. The other condition codes returned by the stack operations include stuck overflow for Push and siaclc emp-ty for Pop and Top. , function words and introducers in this paper  , from training data  , we gather GeneRIF from LocusLink. Experimental results show that DSN-based recommendation performs better compared to when only text similarity is used. These flaws may be in part harming our approach focusing on individual permalinks' topical relevance. It is not known at this stage  , what proportion of the dead links those whose target lies outside WT2g are inter-server links and how many are references to same-server pages which happen to be missing from the VLC2 1 . Many PSLNL documents contain lists of items e.g. GitHub is also a popular code hosting site with a large user base that could provide a relatively diverse pool of potential participants. Upweighting of positive examples: yes w = 5. It is our understanding that any implementation of these approaches would not succeed in improving precision to any usable extent  , if at all when the experiments were based on the WT2g dataset  , due to the lack of Functional links. They concluded that CORI  , and a modified version of the CORI algorithm  , performed reasonably effectively at the server selection task. Similarly to such tasks  , our dataset is composed of a large set of triples coming from LOD datasets  , while our queries consist of entities extracted from news articles and the gold standard is manually created by experts. We consider the area of Central London  , which consists of 3 ,368 street segments. The WebKB dataset contains webpages gathered from university computer science departments. Its score depends on the number of shops  , bars  , restaurants  , and parks on the street extracted from OpenStreetMap and on the street's type. As an example of a QC task  , given the query " apple "   , it should be classified into " Computers\Hardware; Living\Food&Cooking " . However  , there is little tool support for maintaining open  , webaccessible bibliographies to collect relevant publications in dynamic areas  , e.g. In terms of votes  , both Quora and Stack Overflow allow users to upvote and downvote answers. The task is to classify the webpages as student  , course  , faculty or project. This allows us to compare our unsupervised contextualization technique to state-of-the-art techniques  , and possibly to participate in a future WSD challenge. Overflow. Thus it is important to understand how social ties affect Q&A activities. The results of the performance for the TSA algorithm with cross correlation distance function over WS-353 are presented in Table 8. Documents in both D1 and D2 Figure 5 are drawn from dataset collection WT2G where |D1| = |D2| = 2500  , |T1| = 50961 and |T2| = 127487. We analyze the tag distribution of closed and deleted questions and compare them to the overall tag distribution on Stack Overflow. Stack Overflow provides a periodic database dump of all user-generated content under the Creative Commons Attribute- ShareAlike 8 . Accordingly  , the connectivity data was also distributed by ftp in a highly compressed format based on WT2g document numbers. As an example of a case where additional parallelism did not provide any added benefit  , the KDDCup plot for decision trees shows that no improvements in execution time are achieved beyond 32 partitions. As our method also captures co-occurrences of words in a single article as we construct time-series aggregated over all articles on a certain date  , phrases can also be identified well. There are over 100 different badges on Stack Overflow  , which vary greatly in how difficult they are to achieve. Figure 9 shows various quantities of question quality indicators for 'closed' and deleted questions on Stack Overflow . In WPBench  , user interactions are recorded when users are browsing a set of the most popular Web 2.0 applications. We use GitHub as an example of a new class of transparent software environments that incorporate social media features to make work more visible. performance " adopted by KDDCUP 2005 is in fact F1.