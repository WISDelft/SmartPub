Figure 5shows the cumulative latency distributions from both sets of experiments. Although this model can potentially use a lot of bandwidth by sending all updates  , we see little need to optimize the bandwidth consumption for our TPC-W catalog object because the writes to reads ratio is quite small for the catalog information. On the other hand  , RUBiS requires coarser-grain update-intensive services  , but they can be scaled relatively easily. Their study focuses on discovering and explaining the bottleneck resources in each benchmark. We are currently investigating this hypothesis. 18  study the TPC-W benchmark  , including its architecture   , operational procedures for carrying out tests  , and the performance metrics it generates. Because the TPC-W dataset had so little overlap  , we generated a dataset with the same butuseda10-wordvocabulary{w0 ,w1 ,w2 ,â€¦ ,w9}forthe title field. At the same time  , we want to see if our system throughput is competitive with a traditional centralized architec- ture. One should note that GlobeTP has greater effect on the latency in the case of RUBBoS than for TPC-W. We therefore use RR-QID for measurements of TPC-W  , and costbased routing for RUBBoS. We may note that not all forms of data are equally useful for presenting to the user  , including the most popular tagging microformat originally invented for giving hints to the Technorati search engine for categorizing blog posts. We thus examined whether tapping the co-commenting patterns of a user's friends can help improve our personalized recommendation for the user. We varied the load from 140-2500 Emulated Browsers EB. This was intended to tell us whether humans did a better job of categorizing articles than automated techniques. In this paper  , we discuss some initial experiments that aim to determine what tasks are suitable for tags  , how blog authors are using tags  , and whether tags are effective as an information retrieval mechanism. Among the blog document set 100 ,649 feeds 38GB  , 2.8 million permalinks 75GB  , and 325 ,000 homepages 20GB  , only the permalinks were used in our experiment. This can be explained by the fact that in TPC-W the costs of different query templates are relatively similar. The Rice TPC-W implementation includes a workload generator   , which is a standard closed-loop session-oriented client emulator . There are 8 tables and 14 web interactions. Client requests may cycle between the front and back-end database servers before they are returned to the client. According to a recent survey made by Technorati 7  , there are about 75 ,000 new RSS feeds and 1.2 million new stories daily. Technorati. For each tag  , we then collected the 250 most recent articles that had been assigned this tag. For this case study  , we use a fixed sequence of TPC-W requests. Garcia et al. The number of deterministic and probabilistic tuples is in millions. Despite the increased performance  , TPC-W cannot fully utilize the web server's computational resources cf. Brooks and Montanez 4 have studied the phenomenon of user-generated tags to evaluate effectiveness of tagging. He became Principal Engineer for Technorati after working for both Apple and the BBC. As a first step towards providing tools that will assist users in effectively tagging articles  , we tested the similarity of articles that contained similar keywords. Finally  , Section 8 discusses the related work and Section 9 concludes the paper. A sample of English blog data provided by Technorati from a 16 day period in late 2006 shows nearly 403 ,000 unique tags with a mean frequency of 343.1  , median of 8  , and mode of 1. Blog search engines such as Technorati have introduced new features enabling people to find authoritative feeds on a given topic. In TPC-W  , GlobeTP processes 20% more queries within 10 ms than full replication. In TPC-W  , the RR-QID query routing policy delivers better performance than its cost-based counterpart. , BlogPulse and Technorati. In the rest of the paper  , we first present the background information on the TPC benchmark W. Then  , in Section 3  , we discuss the design of our distributed bookstore application with the focus on the four distributed objects that enable data replication for the edge services. Examining this list immediately points out several challenges to users of tags and designers of tagging systems. For example  , in RUBBOS GlobeTP processes 40% more queries than full replication within 10 ms. TPC-W 3  for example includes the WGEN program that populates the benchmark's text attributes using a static collection of words and a grammar. This relatively modest hit rate is due to the fact that the standard TPC- W workload has very low query locality compared to real e-commerce sites 3. Section 6 presents an overview of GlobeDB implementation and its internal performance. However  , typical Web applications issue a majority of simple queries. We choose IBM DB2 for the database in our distributed TPC-W system. We examine blog entries indexed by Technorati and compare the similarity of articles that share tags to determine whether articles that have the same tags actually contain similar content. Figure 1 contains a list of the top 250 tags used by blog writers to annotate their own entries  , collected from Technorati on October 6  , 2005. Table 6shows the obtained results when using the tags  , co-commenting and social signals   , compared to using only the tags and co-commenting signals. This process was conducted recursively  , until no further profiles were discovered. USA elections  , China earthquake  , etc. In the case of SRAA dataset we inferred 8 topics on the training data and labeled these 8 topics for all the three classification tasks discussed above. In all cases we used 4 database servers and one query router. As mentioned in Section 4  , the Newsvine site has a dedicated social network among its users. These servers are connected to each other with a gigabit LAN  , so the network latency between the servers is negligible. SEARCHING FOR PERFORMANCE PROBLEMS IN THE TPC-W BENCHMARK We use the TPC-W Benchmark 24 for evaluation of our approach. This can be seen from the popularity of Technorati tags such as " Baseball "   , " Blogs "   , " Fashion "   , " Funny "   , and so on. The results are reported for the BPR loss function  , which achieved the best results for the Newsvine dataset in accordance with the previous subsection. As shown in Table 2  , this dataset contains 25 ,527 articles with 1 ,664 ,917 comments and 320 ,425 users. For example  , Technorati 1 lists most frequently searched keywords and tags. We began by collecting the 350 most popular tags from Technorati . As we increase the number of database servers  , partial replication performs significantly better than full replication. The fourth collection was obtained by crawling 9 popular blogs from the top popular list presented in Technorati Blog 1 . We deployed the TPC-W benchmark in the edge servers. RDFa data itself contains information using a number of common and less common ontologies  , making it hard to exploit efficiently . TPC-W is an official benchmark to measure the performance of web servers and databases. We evaluate our method on three data sets belonging to three different application areas -spam filtering  , movie review   , and SRAA. We therefore use RR-QID for measurements of TPC-W  , and costbased routing for RUBBoS. It is intended to apply to any industry that markets and sells products or services over the Internet. Both implementations sustain roughly the same throughput. All performance experiments use the TPC-H data set with a probabilistic schema containing uncertainty in the part  , orders  , customer  , supplier  w/P are in Gb. TPC-W defines three transaction mixes: browsing  , shopping  , and ordering mixes. However  , the denormalized TPC-W fails to meet its SLA for two out of the 14 interaction types. For Movie and SRAA data sets  , we give the mean and standard deviation of the classification accuracies over five runs of the classifiers with each run using randomly chosen examples for training and testing. To analyze the impact from various numbers of auxiliary corpora  , we discard Sraa-1 ,2 from Multi-1 ,2 and then applying the C-LDA. In TPC-W  , updates to a database are always made using simple query. For example  , the TPC-W workload has only 14 interactions   , each of which is embodied by a single servlet. In the distributed TPC-W system  , we use this object to manage catalog information  , which contains book descriptions  , book prices  , and book photos. Using TF-IDF 18 to cluster documents and pairwise cosine similarity to measure the similarity of all articles in each cluster  , they found that tags categorize articles in the broad sense. To evaluate the system performance  , we run the TPC-W on four architectures as illustrated in Figure 2 . Furthermore  , the Newsvine friendship relations are publicly crawlable. Similarly  , Mishne & de Rijke 8 showed a strong link between blog searches and recent news -indeed almost 20% of searches for blogs were news-related. The TPC-W application uses a database with seven tables   , which are queried by 23 read and 7 UDI templates. We present here performance evaluations of TPC-W  , which we consider as the most challenging of the three applications. Figure 4shows the throughput scalability of three representative data services from the scalable TPC-W. For various subsets of the datasets discussed above  , we choose number of topics as twice the number of classes. IV. Given that any dynamic Web site has a finite number of interactions  , it is simple to maintain per-servlet estimates. Section 7 presents the relative performance of GlobeDB and different edge service architectures for the TPC-W benchmark. However  , even in this case the system throughput is increased by 33%  , from 450 to 600 EBs. Similar to the previous experiment  , we exercised each system configuration with increasing numbers of EBs until the SLA was violated. The think times of emulated browsers are modeled by using two different MAPs 2  , each with a different burstiness profile. As we will see in the next section   , the throughput improvements that GlobeTP provides are significantly greater for TPC-W than RUBBoS. This is why there has been a variety of efforts to extract information from blog articles. We then compare its performance to " DTW "   , which represents the denormalized TPC-W where no particular measure has been taken to scale up individual services. The most frequently occurring tag is " Weblog " with 6 ,695 ,762 occurrences. While the scores may seem low  , studies on Technorati data by Brooks 4 show cosine In TPC-W  , one server alone can sustain up to 50 EBs. 50 test topics  , each consisting of title phrase  , description sentence  , and narrative paragraph fields  , were constructed using queries from commercial blog search engines e.g. Similar figures are seen for other workload mixes of TPC-W. Other tables are scaled according to the TPC-W requirements. TPC-W benchmark is a web application modeling an online bookstore. We constructed 20 training topics from BlogPulse http://www.blogpulse.com/ and Technorati search http://www.technorati.com/ archives and manually evaluated the search results of the training topics to generate the training data set of 700 blogs. The judges were asked to read each post and then check the boxes next to tags they thought were appropriate for the post. Since the first dataset was crawled from the Newsvine website we could not obtain any click data that can validate which uncommented stories were actually viewed by a user. The distribution of training and testing sets are similar for the Movie and the SRAA data sets. We report the classification accuracy for spam data set  , and the mean and standard deviation of classification accuracy for movie and SRAA data sets calculated over 5 runs of the algorithms. TPC Benchmark W TPC-W is an industry-standard transactional web benchmark that models an online bookstore 34. Similarly  , about 80% of accesses to the customer tables use simple queries. The denormalized TPC-W contains one update-intensive service: the Financial service. This data set was tailor-made to benefit remainderprocessing. The data contains only English content with 8.1M blog posts from 2.7M unique blogs. The Item_basic data service is read-only. Firstly  , Technorati's data is over posts  , not authors  , and  , secondly  , Technorati's index contains a noticable amount of non-post data including weblog home pages and some non-weblog content. Opinion identification is accomplished by combining the four opinion modules that leverage various evidences of opinion e.g  , Opinion Lexicon  , Opinion Collocation  , Opinion Morphology. The first dataset was crawled from the Newsvine news site 1 . However  , the latency and the throughput of a given system are not necessarily correlated. In particular  , TPC-W benchmark defines the catalog update operations as 0.11% of all operations in the workload. While there is clearly great utility in being able to group blog entries into general categories  , this presents a question: do tags provide users with the necessary descriptive power to successfully group articles into sets ? 3  characterize the bottleneck of dynamic web site benchmarks  , including the TPC-W online bookstore and auction site. Our method is a hybrid generative-discriminative method where the term weights represent a generative model and the linear discriminant represents a discriminative model of the classification problem . Table 1presents the list of the crawled blogs. We conducted experiments using TPC-D benchmark data TPC93 o n N T w orkstation running DB2 4 . tagging are not necessarily the ones appearing on pages that are most searched for. To begin  , we randomly selected 250 of the top 1000 tags from Technorati. We conclude this performance evaluation by comparing the throughput scalability of the OTW  , DTW and STW implementations of TPC-W. TPC-W defines three standard workload mixes that exercise different parts of the system: 'browsing' generates 5% update interactions; 'shopping' generates 20% update interactions; and 'ordering' generates 50% update interactions. The co-occurrence matrices are computed on low level categories thus clearer blocks means better clustering performance. Thei_titlefieldoftheitemtablewasgeneratedusing the TPC-W WGEN utility. Some exceptions exist  , like BibSonomy 1 bookmarks + bibtex  , sevenload 2 pictures + video  , or technorati 3 blogs + video. We proceed to describe how each of the datasets was obtained and preprocessed. Amza et al. We compare the similarity of articles that share tags to clusters of randomly-selected articles and also to clusters of articles that share most-relevant keywords  , as determined using TFIDF. These studies prioritize short requests so that they are serviced first  , while our approach actively detects and drops long requests. InLinks We assume that non-personal blogs are more likely to have a large number of incoming links than personal ones  , and use the Technorati Cosmos API 2 to obtain this number. For locking in the database  , think time has an average of 8 seconds and bounded to 80 seconds. The average pairwise Kendall tau correlation of humans with the assigned credibility metric ranking was 0.45. The TPC-W benchmark Online Book Store illustrated a 35 percent improvement in response time for Hilda over a corresponding J2EE implementation. For SRAA dataset we learnt 10 topics on the complete dataset and labeled these 10 topics for all the three classification tasks. We selected 500 of the articles collected from Technorati and  , for each of these articles  , we extracted the three words with the top TFIDF score. Thus it is impossible for a user to read all new stories related to his/her interested topics. It is being used in speech synthesis  , benchmarking  , and text retrieval research. Opinion modules require opinion lexicons  , which are extracted from training data. Unlike TPC-W  , the RUBBoS workload has quite high database query locality. We randomly split SRAA and WebKB datasets such that 80% is used as training data and remaining 20% is used as test data. In Setup B  , the maximal throughput of the benchmark increased to 2200 req/s Curve 3 in Figure 5a. We selected a load of 900 EBs for TPC-W and 330 EBs for RUBBoS  , so that the tested configurations would be significantly loaded. Technorati provided us a slice of their data from a sixteen day period in late 2006. Update operations on catalog data are performed at the backend and propagated to edge servers. The Technorati 1 blog search engine calculates a measure of blog authority as the log of the number of incoming blog links over a six month period 9. He is Vice President of Web Services at BT. These words were then treated as the article's " autotags . " A similar setup to emulate a WAN was used in 15. The TPC-W Benchmark 24 emulates an online bookstore providing twelve different request types for browsing and ordering products and two request types for administrative purposes. But still they are far from being a comprehensive platform for organizing all types of personal data. Comparing the Technorati language breakdown with our author data is not straightforward. For WebKB dataset we learnt 10 topics. We compare three implementations of TPC-W. " OTW " represents the unmodified original TPC-W implementation. Another metric is the Web Interaction Response Time  , WIRT  , which is used for measuring the latency of the system. One should note that GlobeTP has greater effect on the latency in the case of RUBBoS than for TPC-W.