The WT2g connectivity data see http://pastime.anu.edu.au/WAR/WT2g_Links/ilink_WTonly.gz and the Small Web qrels file were used to find the set of documents which link directly to relevant documents. For Reuter-21578  , we used a subset consisting of 10 ,346 documents and 92 categories. This gap indicates the increased inference variance inherent in approximate inference approaches. Typically  , classification accuracies averaged over all the six classes are published with WebKB and are usually in the 70 − 90% range depending on the choice of features. To evaluate DoSeR as well as the competitive disambiguation systems we use the GERBIL -General Entity Annotator Benchmark 23  which offers an easy-touse platform for the agile comparison of annotators using multiple data sets. Given the datasets above  , we now describe how we tested and measured the efficacy of the recommendation algorithms described in Sections 2 and 3. Results of the experiments run on the Gerbil platform are shown in Table 2. We employ five different document selection methodologies that are well studied in the context of evaluation  , along with the method used in LETOR for comparison purposes. Actually  , full-fledged functional templating is supported only by MediaWiki and Wikia which is MediaWikibased . Figure 2: Performance trend MAP as the single smoothing hyper-parameter λ  , µ  , and ω changes for each language model on the WT2g tuning collection for description only queries top and for description and narrative queries bottom. The approaches from this line of research that are closest to CREAM is the SHOE Knowledge Annotator 10 and the WebKB annotation tool. All presented NDCG  , Precision and MAP results are averaged across the test queries and were obtained using the evaluation script available on the LETOR website. Our combination method is also highly effective for improving an n-way classifier. In particular  , in the WebKB task  , the attributes significantly impair RDN performance. In LETOR  , there are a total of 16 ,140 query-document pairs with relevance judgments  , and 25 extracted features. Table 9gives the numbers of directly and indirectly relevant documents. On the other three collections  , the performance of all the three PRoc models is very close. Next  , we experiment with the extent that the algorithms can produce quality recommendations for groups  , using the MoviePilot data. For instance  , the most popular of these services  , Wikia 2   , has more than three thousand collections  , some of them with more than fifty thousand documents. There are 16 ,140 query-document pairs with relevance labels. We conducted 5-fold cross validation experiments  , following the guideline of Letor. Since GERBIL is based on the BAT-framework  , annotators of this framework can be added to GERBIL easily. Our survey comprised five developers with expert-level programming skills in Java. A 10% sample was taken which maintained the same distribution of intrusions and normal connections as the original data this sample is available as kddcup .data. Most notably  , we have only reported MAP scores for the MoviePilot data. This is because SimFusion+ uses UAM to encode the intra-and inter-relations in a comprehensive way  , thus making the results unbiased. Since we are only training on a single topic  , resulting accuracy is far lower than what typically published LETOR results. A search for " internet service provider " returned only Earthlink in the top 10. From the Wikia service  , we selected the encyclopedias Wookieepedia  , about the Star Wars universe  , and Muppet  , about the TV series " The Muppet Show " . The online version of GERBIL can be accessed at http://gerbil.aksw.org/gerbil. As shown in Figure 2  , the documents selected by the two methods also exhibit very high similarity to each other. These data sets were chosen because they are publicly available  , include several baseline results  , and provide evaluation tools to ensure accurate comparison between methods. It is accessible at http://gerbil.aksw.org/gerbil/ experiment ?id=201503050003 visualizations  , 30 see Figure 2 . The results on seven datasets in LETOR 3.0 show that the NDCG-Annealing algorithm can outperform the baselines and it is more stable. Hence  , by using GERBIL for experiments  , tool developers can ensure that the settings for their experiments measures  , datasets  , versions of the reference frameworks  , etc. Given an aggregate ranking π  , and relevance levels L  , NDCG is defined as: Thereafter  , we present the GERBIL framework. Currently  , GERBIL offers 9 entity annotation systems with a variety of features  , capabilities and experiments. See Figure 4for an example of the results generated by a query "Vegetable Soup Recipes". All experiments were performed on a 1GHz Pentium III processor with 1GB RAM running Linux kernel 2.4. By these means  , we allow benchmarking tools against reference datasets from any domain grounded in any reference knowledge base. By this method  , an input query is first mapped to an intermediate category  , and then a second mapping is applied to map the query from the intermediate category to the target category. In Section 5  , we compare the approaches empirically on the tasks of KDDCUP 2005 competition. The output of experiments as well as descriptions of the various components are stored in a serverless database for fast The Ohsumed data set is available from the LETOR website 1 . These are the two Wikia encyclopedias with the largest number of articles evaluated by users regarding their quality. GER- BIL will regularly check whether new corpora are available and publish them for benchmarking after a manual quality assurance cycle which ensures their usability for the implemented configuration options. Table 2shows k-means clustering results on the WebKB 4 Universities data set. We bridge the gap between entities and text using automatic information extraction to identify entities and link them to a knowledge base. We also used the MoviePilot data  , by disregarding the group memberships. Automatic knowledge base population by extracting entity information from large-scale unstructured text data has been shown to be a very challenging task in the recent TAC KBP program 1 . We then transformed the dataset into "course" and "non-course" target values. The WebKB dataset consists of 8275 web-pages crawled from university web sites. Our approach was based on using the WT2g dataset  , consisting of 247 ,491 HTML documents at 2GB storage requirements. Zhu  , Kraut  , and Kittur 2014 examine community survival as a function of multiple memberships within Wikia communities. Applying our utility function to SVD leads to a new utility function SV D util in this paper. The assessors checked the number of relevant documents in the Web collection once they had a candidate topic from searching the ad hoc collection. For all the SVM models in the experiment  , we employ the linear SVM. In the future  , we also plan to provide information about the point in time since when an annotator is stable  , i.e. Therefore  , in the case where hundreds of raw features are employed  , ranking functions may need more than 1% of the complete collection to achieve optimal performance. GERBIL abides by a service-oriented architecture driven by the model-view-controller pattern see Figure 1. The SHOE Knowledge Annotator is rather a little helper like our earlier OntoPad 12  , 5 than a full fledged annotation environment. We also see from Figure 4 that our NDCG-Annealing algorithm outperforms all the other baseline algorithms on this dataset. provide the source code 25 as well as a webservice. The results of RankSVM  , RankBoost  , AdaRank and FRank are reported in the Letor data set. Our approach generally outperforms IG  , and the advantage becomes larger with the increase of data size. 52 % of these links reference another document within WT2g but only 0.12 % reference a different server within WT2g. With GERBIL we introduce the notion of knowledge base-agnostic benchmarking of entity annotation systems through generalized experiment types. KDDCUP 2005 provides a test bed for the Web query classification problem. We use the 5-fold cross validation partitioning from LETOR 10. However  , GERBIL is currently only importing already available datasets. In our solution  , an intermediate taxonomy is used to train classifiers bridging the queries and target categories so that there is no need to collect the training data. We begin by giving an overview of related work. BRFS performance matched or exceeded in some cases SS1 and BL. This can be attributed to larger categorical attribute dependencies being used in the detection process for the KDDCup data set. Table 7: Optimal hyper-parameter on all retrieval methods over both types of verbose queries tuned for MAP on WT2g.  We evaluate Section 4 the probabilistic model alongside state-of-the-art CF approaches  , including popularity based  , neighbourhood  , and latent factor models using household rating data from MoviePilot 1 . We evaluate our algorithm on the purchase history from an e-commerce website shop.com. Exact inference also reduces error as the STACKED- GIBBS approach performs significantly worse p < 0.05 than the STACKED model in every dataset except WebKB. Each observation features the qb:Dimensions experiment type  , matching type  , annotator   , corpus  , and time. For WebKB  , we used a subset containing 4 ,199 documents and four categories. The experimental results provided in the LETOR collection also confirm this. Though our method of link-content matrix factorization perform slightly better than other methods  , our method of linkcontent supervised matrix factorization outperform significantly. In the first experiment  , we used the Letor benchmark datasets 18: OHSUMED  , TD2003  , and TD2004. The dataset contained 476 abstracts  , which were divided into four research areas: Natural Language Processing NLP  , Robotics/Vision  , Systems  , and Theory. More information can be found at our project webpage http:// gerbil.aksw.org and at the code repository page https: //github.com/AKSW/gerbil. We compare our proposed NDCG-Annealing algorithm with those baselines provided in LETOR 3.0.