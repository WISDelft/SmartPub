Our best All­data machine learning classifier, averaged over five randomized iterations, improved over MVR general practitioner accuracy on most metrics. __label__=others
Compared with MVR results, the All­data model was less conservative (lower specificity) but better able to positively identify observations from depressed individuals (higher recall). __label__=result
Given 100 observations, our model correctly identified 70% of all depressed cases (n=37), with a relatively low number of false alarms (n=23) and misses (n=17). __label__=others
Pre­diagnosis predictions showed improvement over the MVR benchmark on precision and specificity. __label__=result
The Pre­diagnosis model found only about a third of actual depressed observations, but it was correct most of the time when it did assign a depressed label. __label__=result
By comparison, although MVR general practitioners discovered more true cases of depression, they were more likely than not to misdiagnose healthy subjects as depressed. __label__=others
Out of the four predictors used in the human ratings model (happiness, sadness, likability, interestingness), only the sadness and happiness ratings were significant predictors of depression. __label__=others
Depressed participants' photos were more likely to be sadder and less happy than those of healthy participants. __label__=others
Ratings assessments generally showed strong patterns of correlation with one another, but exhibited extremely low correlation with computational features. __label__=result
The modest positive correlation of human­rated happiness with the presence and number of faces in a photograph was the only exception to this trend. __label__=others
Correlation matrices for all models are available in Appendix IX. __label__=others
.The present study employed machine learning techniques to screen for depression using photographs posted to Instagram. __label__=dataset
Our results supported Hypothesis 1, that markers of depression are observable in Instagram user behavior, and Hypothesis 2, that these depressive signals are detectable in posts made even before the date of first diagnosis. __label__=dataset
Human ratings proved capable of distinguishing between Instagram posts made by depressed and healthy individuals (Hypothesis 3a), but showed little or no correlation with most computational features (Hypothesis 3b). __label__=dataset
Our findings establish that visual social media data are amenable to analysis of affect using scalable, computational methods. __label__=method
One avenue for future research might integrate textual analysis of Instagram posts' comments, captions, and tags. __label__=dataset
Considering the early success of textual analysis in detecting psychological signals on social media (5,33), the modeling of textual and visual features together could prove superior to either medium on its own. __label__=others
Our model showed considerable improvement over the ability of unassisted general practitioners to correctly diagnose depression. __label__=result
On average, more than half of general practitioners' depression diagnoses were false positives (24). __label__=others
By comparison, the majority of both All­data and Pre­diagnosis depression classifications were correct. __label__=others
As false diagnoses are costly for both healthcare programs and individuals, this improvement is noteworthy. __label__=others
Health care providers may be able to improve quality of care and better identify individuals in need of treatment based on the simple, low­cost methods outlined in this report. __label__=method
Given that mental health services are unavailable or underfunded in many countries (34), this computational approach, requiring only patients' digital consent to share their social media histories, may open avenues to care which are currently difficult or impossible to provide. __label__=method
Although our Pre­diagnosis prediction engine was rather conservative, and tended to classify most observations as healthy, its accuracy likely represents a lower bound on performance. __label__=others
Ideally, we would have used the All­data classifier to evaluate the Pre­diagnosis data, as the All­data model was trained on a much larger dataset. __label__=dataset
Since the Pre­diagnosis data constituted a subset of the full dataset, applying the All­data model to Pre­diagnosis observations would have artificially inflated accuracy, due to information leakage between training and test data. __label__=dataset
Instead, we trained a separate classifier using training and test partitions contained within the Pre­diagnosis data. __label__=others
This left the Pre­diagnosis model with considerably fewer data points to train on, resulting in weaker predictive power. __label__=result
As a result, it is likely that Pre­diagnosis accuracy scores understate the method's true capacity. __label__=method
Regarding the strength of specific predictive features, some results matched common perceptions regarding the effects of depression on behavior. __label__=result
Photos posted to Instagram by depressed individuals were more likely to be bluer, grayer, darker, and receive fewer likes. __label__=dataset
Depressed Instagram users in our sample had an outsized preference for filtering out all color from posted photos, and showed an aversion to artificially lightening photos, compared to healthy users. __label__=dataset
These results are congruent with the literature linking depression and a preference for darker, bluer, and monochromatic colors (16­19). __label__=result
Other, seemingly intuitive, relationships failed to emerge. __label__=result
For example, the sadness of a photo, and the extent to which it is bluer, darker, and grayer than other photos, seem like close semantic matches. __label__=result
Despite both being strong predictors of depression, however, sadness ratings and color were statistically unrelated. __label__=others
Algorithmic face detection yielded intriguing results. __label__=method
Depressed users were more likely to post photos with faces, but they tended to post fewer faces per photo. __label__=others
Fewer faces may be an oblique indicator that depressed users interact in smaller social settings, which would be in accordance with research linking depression to reduced social interactivity (5,20,21). __label__=others
That depressed Instagram users posted more photos with faces overall, however, offers less clear interpretation. __label__=dataset
Depressed individuals have been shown to use more self­focused language (35), and it may be that this self­focus extends to photographs, as well. __label__=result
If so, it may be that the abundance of low­face­count photos posted by depressed users are, in fact, self­portraits. __label__=others
This " sad selfie " hypothesis remains untested. __label__=others
A limitation of these findings concerns the non­specific use of the term " depression " in the data collection process. __label__=result
We acknowledge that depression describes a general clinical state, and is frequently comorbid with other conditions. __label__=others
It is possible that a specific diagnostic class is responsible for driving the observed results, and subsequent research should adjust questionnaires to acquire specific diagnostic information. __label__=result
Additionally, it is possible that our results are specific to individuals who received clinical diagnoses. __label__=result
Current perspectives on depression treatment indicate that people who are " well­informed and psychologically minded, experience typical symptoms of depression and little stigma, and have confidence in the effectiveness of treatment, few concerns about side effects, adequate social support, and high self­efficacy " seek out mental health services (25). __label__=result
The intersection of these qualities with typical Instagram user demographics suggests caution in making broad inferences about depression, based on our findings. __label__=dataset
As the methods employed in this research provide a tool for inferring personal information about individuals, two points of caution should be considered. __label__=software
First, data privacy and ethical research practices are of particular concern, given recent admissions that individuals' social media data were experimentally manipulated or exposed without permission (36,37). __label__=others
It is perhaps reflective of a current general skepticism towards social media research that, of the 509 individuals who began our survey, 221 (43%) refused to share their Instagram data, even after we provided numerous privacy guarantees. __label__=dataset
Future research should prioritize establishing confidence among experimental participants that their data will remain secure and private. __label__=others
Second, data trends often change over time, leading socio­technical models of this sort to degrade without frequent calibration (38). __label__=others
The findings reported here should not be taken as enduring facts, but rather as a methodological foundation upon which to build and refine subsequent models. __label__=method
Paired with a commensurate focus on upholding data privacy and ethical analytics, the present work may serve as a blueprint for effective mental health screening in an increasingly digitalized society. __label__=others
More generally, these findings support the notion that major changes in individual psychology are transmitted in social media use, and can be identified via computational methods. __label__=method
.This study was reviewed and approved by the Harvard University Institutional Review Board, approval #15­2529 and by the University of Vermont Institutional Review Board, approval #CHRMS­16­135. __label__=others
All study participants were informed of and acknowledged all study goals, expectations, and procedures, including data privacy procedures, prior to any data collection. __label__=others
Surveys were built using the Qualtrics survey platform. __label__=others
Analyses were conducted using the Python and R programming languages. __label__=others
Social media data collection apps were written in Python, using the Instagram developer's Application Programming Interface (API). __label__=software
The survey for depressed participants collected age data from participants, and asked qualified participants questions related to their first depression diagnosis and social media usage at that time. __label__=dataset
These questions were given in addition to the CES­D scale. __label__=others
The purpose of these questions was to determine: ● The date of first depression diagnosis ● Whether or not the individual suspected being depressed before diagnosis, and, ● If so, the number of days prior to diagnosis that this suspicion began In the case that participants could not recall exact dates, they were instructed to approximate the actual date. __label__=result
The survey for healthy participants collected age and gender data from participants. __label__=dataset
It also asked four questions regarding personal health history, which were used as inclusion criteria for this and three other studies. __label__=others
These questions were as follows: ● Have you ever been pregnant? __label__=others
● Have you ever been clinically diagnosed with depression? __label__=others
● Have you ever been clinically diagnosed with Post­Traumatic Stress Disorder? __label__=others
● Have you ever been diagnosed with cancer? __label__=others
Participants' responses to these questions were not used at all in analysis, and only served to include qualified respondents in each of the various studies, including the depression­related study reported here. __label__=others
.We used an elementary face detection script, based on an open source demonstration (https://gist.github.com/dannguyen/cfa2fb49b28c82a1068f). __label__=method
The main adjustment we made from the open source demo was to run through the detection loop twice, using two differing scale factors. __label__=others
A single scale factor had difficulty finding both small and large faces. __label__=result
Parameters used: scale_factors = [1.05, 1.4], min_neighbors = 4, min_size = (20px,20px) Algorithm accuracy was assessed by manually coding a random sample of 400 photos (100 photos from each of combination of depressed/healthy, detected/undetected). __label__=method
Detection accuracy was roughly equal across groups: Face detection accuracy: Depressed, No face detected: 77% accurate Healthy, No face detected: 79% accurate Depressed, 1+ faces detected: 59% accurate Healthy, 1+ faces detected: 61% accurate .The mean difference in counted faces (detected faces minus actual faces), indicated that the algorithm slightly undercounted the number of faces in photos, for both depressed participants as well as healthy participants . __label__=method
In both groups, μ − .015, σ .21) Table S1. __label__=result
Summary statistics for data collection (N=43,950). __label__=others
.Bayesian logistic regression A Bayesian framework avoids many of the inferential challenges of frequentist null hypothesis significance testing, including reliance on p­values and confidence intervals, both of which are subject to frequent misuse and misunderstanding (39­42). __label__=software
For comparison, results from frequentist logistic regression output are included below; both methods are largely in agreement. __label__=method
Logistic regression was conducted using the ​ MCMClogit​ function from the R package MCMCpack​ (43). __label__=others
This function asserts a model of the following form : With the inverse link function: And a multivariate Normal prior on í µí»½: We selected " uninformative " priors for all parameters in í µí»½, with While , .0001. b 0 = 0 B 0 = 0 generally it is preferable to specify Bayesian priors, in this setting our parameters of interest were entirely novel, and so were not informed by prior literature or previous testing. __label__=others
The ​ MCMClogit()​ function employs a Metropolis algorithm to perform Markov Chain Monte Carlo (MCMC) simulations. __label__=method
The Instagram model simulation used two MCMC chains of 100,000 iterations with a burn­in of 10,000 and no thinning. __label__=dataset
The use of thinning for achieving higher­precision estimates from posterior samples is questionable when compared to simply running longer chains (44). __label__=result
While no best practice has been established for how long an unthinned chain should be, Christensen et al. __label__=others
(45) advised: " Unless there is severe autocorrelation, e.g., high correlation with, say [lag]=30, we don't believe that thinning is worthwhile " . __label__=others
In our MCMC chains, we observed low autocorrelation at a lag of 30, and so felt confident in foregoing thinning. __label__=result
For comparison, we also ran a 100,000­iteration chain, thinned to every 10th iteration, with a burn­in of 5,000. __label__=others
While autocorrelation was noticeably reduced at shorter lags, this chain yielded near­identical parameter estimates from the posterior. __label__=others
Recall that Bayesian regression coefficients are not assigned p­values or any other significance measures conventional in frequentist null­hypothesis significance testing (NHST). __label__=others
We have provided Highest Posterior Density Intervals (HPDIs) for the highest probability at which the interval excludes zero as a possible coefficient value. __label__=others
For example, if a 99% HPDI is reported, it means that, based on averaged samples from the simulated joint posterior distribution, the coefficient in question has a 99% probability of being non­zero. __label__=others
References to variable " significance " in the Results section relate only to the probability that a variable's parameter estimate is non­zero, eg. " __label__=others
Variable X was significant with 99% probability " . __label__=others
Bayes factors were used to assess model fit. __label__=others
: Decisive K &gt; 10 2 Markov Chain Monte Carlo (MCMC) chains showed good convergence across all estimated parameters on every fitted model. __label__=result
In all models, Gelman­Rubin diagnostics (47) indicated simulation chain convergence, with point estimates of 1.0 for each parameter. __label__=result
Geweke diagnostics (48) also indicated post­burn­in convergence. __label__=result
Autocorrelation was observed within acceptable levels. __label__=result
Trace, density, and autocorrelation plots for all models are presented in SI Appendix V. Machine learning models We employed a suite of supervised machine learning algorithms to estimate the predictive capacity of our models. __label__=method
In a supervised learning paradigm, parameter weights are determined by training on a labeled subset of the total available data ( " labeled " here means that the response classes are exposed). __label__=others
Fitted models are then used to predict class membership for each observation in the remaining unlabeled " holdout " data. __label__=others
All of our machine learning classifiers were trained on a randomly­selected 70% of total observations, and tested on the remaining 30%. __label__=others
We employed stratified five­fold cross­validation to optimize hyperparameters, and averaged final model output metrics over five separate randomized runs. __label__=method
, None] In evaluating binary classification accuracy, a simple proportion of correct classifications ( " naive accuracy " ) is often inappropriate. __label__=others
In cases where data exhibit a class imbalance, i.e. __label__=others
more healthy than depressed observations (or vice­versa), reporting naive accuracy can be misleading. __label__=others
(A classification accuracy of 95% seems excellent until it is revealed that 95% of the data modeled belong to a single class.) __label__=result
Additionally, naive accuracy scores are opaque to the specific strengths and weaknesses of a binary classifier. __label__=others
Instead, we report precision, recall, specificity, negative predictive value, and F1 scores for fuller context. __label__=result
V. MCMC Diagnostics All­data model Fig. __label__=others
S1. __label__=others
Trace and density plots for All­data model MCMC simulations. __label__=others
Fig. __label__=others
S2. __label__=others
Autocorrelation plot for All­data model MCMC simulations. __label__=others
First chain only is displayed for conciseness (second chain output is nearly identical). __label__=others
suggested that a model with good replication accuracy should generate posterior predictive p­values within the range of 0.05­0.95. __label__=result
Note that an extreme posterior predictive p­value does not mean that a model is wrong, just that it fails to be " right enough " to render a reasonable replication of its input. __label__=others
All models nevertheless far outperformed a simple null model in the capacity to correctly predict class membership. __label__=others
Table S4. __label__=result
Logistic regression output for Ratings model (N=8,976). __label__=others
HPD Level = Highest Posterior Density Level, the probability that a regression coefficient falls within the given HPD Interval. __label__=others
HPD Levels listed are highest probabilities with which it can be claimed that a coefficient's HPD Interval excludes zero. __label__=others
A posterior predictive check of Ratings model showed that sample observations replicated from the joint posterior distribution accurately represented the true proportion of depressed observations (replicated: 44.2% depressed; original: 43.9%), with a posterior predictive p­value of 0.516. __label__=result
VIII. __label__=others
Instagram filter examples Fig. __label__=dataset
S8 __label__=others

These findings suggest new avenues for early screening and detection of mental
illness __label__=objective
Specifically, when queried for a given user-id this API provides: (i) the user's profile information including a location-tag introduced by the user, (ii) a list of followers user-ids and (iii) other information such as the number of friends of the user and the number of tweets posted by the user so far. __label__=software
For our study we have analyzed a random set of 2M users obtained from [10]. __label__=method
For each one of these users we have collected the geographical location of the user, the number of friends, posted tweets and followers. __label__=others
Furthermore we have also used the API to find the geographical location of all the followers of each analyzed user. __label__=software
Unfortunately, Twitter limits the number of queries to be performed to 350 per hour per IP address/user-id 1 . __label__=dataset
Therefore, in order to speed up the data collection process we developed a master-slave distributed measurement architecture. __label__=method
This architecture counts with 1 master and 20 slaves located in different virtual machines on top of two physical machines. __label__=others
The master indicates to each slave the user-ids to be monitored. __label__=others
Furthermore , each slave has its own IP address and user-id and can then perform 350 queries per hour to the Twitter API. __label__=software
Therefore, by using this distributed measurement architecture we are able to perform up to 7K queries per hour. __label__=others
Finally, the slaves store the collected information into a redundant centralized database. __label__=dataset
The collected user's location is the one provided by the user himself in his Twitter profile. __label__=dataset
Hence, it is not homogeneous and in some cases non-existing or meaningless . __label__=others
Our measurement tool filters those users that do not provide location information or provide a meaningless location. __label__=software
Furthermore we use the Yahoo cation API [3] in order to homogenize the obtained data. __label__=software
For instance, all those users indicating NY, NYC, New York City, etc are mapped into the same city, i.e. __label__=result
New York City. __label__=others
It is worth to mention that in Appendix A we demonstrate that the location-tag provided by the user in its profile accurately defines the geographical location of the user. __label__=result
We have crawled the Twitter API with the described software from 10-01-2011 until 28-04-2011. __label__=software
The resulting dataset includes (after filtering it) 973K geolocated friends, 16.5M of geolocated followers and more than 100M of friend→follower relationships. __label__=dataset
.In this section we quantify the level of Locality of the friends→followers graph in Twitter. __label__=dataset
This is, we aim to answer the following question: Are followers typically located close to its friends?. __label__=others
For this purpose we use the two following metrics: -link level distance: the geographical distance for each individual friend→follower link in our dataset. __label__=dataset
-user level distance: the median geographical distance between a friend and its followers population. __label__=others
Figure 1(a) represents the CDF for both metrics. __label__=result
If we focus first on the link level distance, we observe that 35% of the links have an associated distance lower than 1000 km. __label__=result
This represents intra-country communications for the most representative countries in our dataset (See Tab 1). __label__=dataset
Furthermore, we observe that 67% of the links are in a range of 4000 km, which means intra-country communications for big countries such as US or Brazil and intra-continent relationships for western Europe. __label__=result
However, there is still around 25% of long-distance links over 6500 km that represent crosscontinent links. __label__=others
Therefore, we can conclude that Twitter is not a very highly localized system. __label__=dataset
It must be noted that the link level distance analyzes individual links and does not capture well the Locality at the user level, since popular users with millions of followers have a higher impact in the presented distribution than those unpopular users. __label__=method
The user level distance instead, avoids this effect. __label__=others
We observe that the distribution at the user level is more skewed than the previous one. __label__=others
Specifically, 80% of the users have a typical distance to its followers ≤ 4000 km (i.e. __label__=others
intra-country or intra-continent links). __label__=others
Hence, the user level depicts a higher intra-country locality than the link level. __label__=others
This suggests that popular users (i.e. __label__=result
those with a larger number of followers) are responsible for most of the long-distance links and has a typical distance to its followers larger than those unpopular users. __label__=others
In order to confirm this hypothesis we group the users by its popularity 2 (i.e. __label__=others
number of followers) and for each group we calculate the median for user and link level distances. __label__=others
The results are depicted by Figure  1(b). __label__=result
The figure validates the previous hypothesis, since we observe that the more popular a user is, the larger is also the distance to its followers population. __label__=result
In summary, we have demonstrated that Twitter is not a highly localized system at the link level since there is an important portion of long-distance relationships whereas the localization is more marked at the user level. __label__=dataset
Furthermore, we have seen that popularity clearly impacts the Locality level of the users. __label__=result
However, this global analysis is clearly influenced by the dominance of US that represents 50% of the friends, followers and links in our dataset (See Table 1 ). __label__=dataset
Therefore, in the rest of the paper we will deepen and broad the study by analyzing geo-political, cultural and language aspects in order to answer the following questions: Are the reported global observations valid for every country? __label__=others
What are the causes of the observed distribution of intra-country, intra-continent and cross-continent relationships?. __label__=others
.In this section we group the friends in our dataset by country. __label__=dataset
We have selected the country criteria since it allows to accurately group those friends having a close geographical location, a similar cultural profile and the same language. __label__=others
We first study the demographics of our dataset, and later perform a country-based analysis of link level and user level Locality. __label__=dataset
.In order to study the demographics of our dataset we select the 15 countries contributing a larger number of friends. __label__=dataset
The detailed demographic numbers of each one of these 15 countries are summarized in Table 1. __label__=result
Note that overall these 15 countries are responsible for around 90% of our dataset. __label__=dataset
First, as already stated, we observe that US is the predominant country in Twitter responsible for around half of the friends, followers and links in our dataset. __label__=dataset
Furthermore, from the language perspective we differentiate two profiles. __label__=others
On the one hand, we have those countries whose official (or coofficial ) language is the English such as US, Canada, UK, Ireland, India and Australia. __label__=others
On the other hand, we find those countries with a different official language than English such as Brazil, Spain, Germany, France, Italy, Indonesia, Japan and the Netherlands. __label__=result
Finally, it is worth to note the presence of developing countries such as Brazil, India and Mexico in the list. __label__=others
This is mainly due to the high population of these countries that eases to contribute a large number of users but also indicates the interest of their population on new social ways of communication such as Twitter. __label__=dataset
Once we know the basic demographics of our dataset, our second aim is understanding what is the level of intra-country Locality and inter-country interaction in Twitter at link and user levels. __label__=dataset
.For each one of the Top 15 countries we compute the percentage of links originated in the country that: (i) remains within the country, (ii) goes to US and, (iii) goes to a different country than US. __label__=others
Figure 2depicts the obtained results. __label__=result
As expected, the observed global Locality trends do not apply to every country and are mostly influenced by US Locality properties. __label__=others
Based on our observations we can distinguish 4 different profiles: US: due to its predominant role, it has to be considered as a separated profile. __label__=others
It keeps more than a 70% of friend→follower relationships local. __label__=others
This is consequence of first, the predominance of US users in Twitter and second the strong local culture of US. __label__=dataset
Local profile: This is formed by a group of countries keeping local a higher number of links than those going to US or other countries. __label__=others
This is Local &gt; US &amp; Local &gt; Other in Figure 2. __label__=result
This profile includes Brazil, The Netherlands, Indonesia, Germany and Spain. __label__=others
All these countries have an official language different than English . __label__=others
Furthermore, we found also some significant differences within the group. __label__=result
On the one extreme, Brazil is the country showing the highest Locality in our dataset with almost 80% of local links. __label__=dataset
This is because it is a big country with a strong local culture and the spoken language (Portuguese) is not very spread. __label__=others
Just other countries, not very representative in Twitter, such as Portugal use Portuguese. __label__=dataset
On a different corner, we have Spain whose local links are reduced to a 41%, since now many relations (around 30%) are established with South-America (common language) and other European countries (member of EU). __label__=others
Shared Locality profile: This is formed by those countries that distribute their friend→follower links equally among those that remain local, those that go to US and those that go to other countries. __label__=others
This profile includes France, Mexico, Italy and Japan that are those countries where Twitter is less popular among the studied ones. __label__=dataset
Therefore, at the individual link level, intracountry Locality has a strong dependency with the local popularity of Twitter, we expect a lower intra-country Locality happening in those countries where Twitter is less popular. __label__=dataset
English-based (external) Locality profile: This is formed by countries where English is the official or coofficial language. __label__=others
These countries concentrate the major part of their links among them. __label__=others
Specifically, they experience an important external Locality with many friend→follower links going to US (e.g. __label__=others
48% in the case of India and 47% in the case of Australia and Canada). __label__=others
Furthermore, a lower but also important portion of links stay local (e.g. __label__=others
34% in the case of UK and 31% in the case of Canada) and the rest are shared mainly with other English speaking countries and surrounding countries . __label__=others
Therefore in this case, we observe that the combination of language and demographics clearly influences the Locality associated to these countries. __label__=result
. __label__=others
The analysis performed so far has focused on understanding the Locality at the link level. __label__=others
However, as we have seen in Section 3 this analysis may not capture well the details at the user level. __label__=result
Next, we thoroughly analyze Locality at the user level for the Top 15 countries . __label__=method
Due to space constrains in this paper we provide the detailed analysis of one country per profile. __label__=others
ically, we consider the country with a larger number of users from each profile in our dataset. __label__=dataset
These are: US, Brazil, UK and France. __label__=others
For each one of the selected countries we repeat the analysis performed in Section 3. __label__=others
First, Figure 3presents the distribution of link level and user level distances for each country. __label__=result
We confirm that in any case there is a higher Locality at the user level (curve more skewed) than at the link level. __label__=others
Let's now study separately each country. __label__=others
We observe that around 90% of US users have typically a distance to its followers ≤ 4000km that defines the boundary of intra-country relationships for US. __label__=others
This intra-country locality effect is even more impressive in Brazil where 90% of the users have a user level distance ≤ 2000km, when the limit of intra-country relationships is also about 4000km. __label__=others
This confirms the presence of a regional-based Locality in Brazil. __label__=others
If we analyze UK, it shows, at the user level, the bi-polarity described above between UK and US. __label__=method
However, contrary to the link level (34% local, 42% US), the user level presents a 50% of local followers in the range of 1000Km, while those ones located in US are now reduced to a 37%. __label__=others
The second European country analyzed, France, has a 60% of its followers closer than 1000km. __label__=method
However several neighbor countries such as Belgium, The Netherlands, Switzerland, Italy and Germany are located within this distance range. __label__=others
Hence, some portion of this 60% represents inter-country relationships rather than intra-country ones. __label__=others
Finally, around 1/3 of the french users have a typical distance to its followers between 5500 and 9500 km, which represents followers population in US. __label__=others
Then the described shared profile is also valid at the user level. __label__=others
Second, we analyze how the popularity affects the Locality for the users of each one of the studied countries. __label__=method
We use the same methodology explained in Section 3. __label__=method
Figure 4 shows the obtained results. __label__=result
We observe significant differences among the countries. __label__=others
US shows an important correlation between popularity and Locality. __label__=result
The higher the popularity is the longer are the user's friend→follower links. __label__=others
The curves from US are similar to those observed for the whole system (See Figure 5: Percentage of Local followers vs Percentage of Followers in US (top) and other countries (bottom) per individual user: US, UK, France and Brazil nal followers, whereas in US we observe a slightly lower intra-country locality effect since US friends present a percentage of local followers between a 70% and 90%. __label__=result
Looking at the European countries, we observe a higher level of localization in France where the vast majority of users are concentrated between 40% and 80% of local followers, whereas the UK shows a less concentrated diagram covering from 20% to 80% of local followers. __label__=result
Furthermore, we observe how the remote followers of UK are more concentrated in US whereas French users tend to have more followers from other countries different than US. __label__=result
.Twitter Measurements: Several previous works have exploited the different APIs offered by Twitter in order to collect data and describe different characteristic of the system. __label__=software
Krishnamurthy et al. __label__=others
[9] performed one of the initial measurement studies on Twitter collecting data of 100K users. __label__=dataset
The authors report basic characteristics of the system such as the correlation between number of followers and friends of a given user or the distribution of Twitter users per continent. __label__=dataset
Afterwards Kwak et al. __label__=others
[10] collected the complete friend→follower Twitter graph including 41.7 million users at the moment of the study. __label__=dataset
The authors analyze the properties of the graph topology as well as some other social aspects of Twitter such as the users influence. __label__=dataset
Also in the field of users influence Cha et al. __label__=others
[4] use a large dataset in order to analyze the dynamics of user influence across topic and time in Twitter. __label__=dataset
Finally, some other studies [7, 8, 15] focus on understanding social aspects of the Twitter system. __label__=dataset
However, to the best of our knowledge any of the previous studies looks at neither the location of a user's followers or the Locality effect in Twitter. __label__=dataset
. __label__=others
in the Internet: Locality is an important aspect to be considered in large scale applications. __label__=others
Having it into consideration may help to improve the system design and performance as has been demonstrated for the case of p2p file-sharing applications [5, 6, 14], p2p live-streaming applications [11] or OSNs such as Facebook [13]. __label__=dataset
Although Twitter has significant different characteristics than p2p applications and slightly different than Facebook, considering the Locality effect in the system design may help to improve the performance and also the data storage procedure [12] of Twitter. __label__=dataset
.Understanding the Locality effect of Internet scale systems have direct implications into the improvement and performance of such a systems. __label__=others
This paper is, to the best of the authors knowledge, the first study regarding the Locality phenomenon in Twitter. __label__=dataset
The obtained results demonstrate that different countries show different Locality profiles mostly influenced by the language and cultural characteristics of the country. __label__=result
On the one corner, we have countries with an extremely high intra-country Locality such as Brazil where most of its users keep local 80 to 90% of the followers. __label__=others
On the other extreme, we have countries experiencing an external Locality phenomenon such as Australia where 50% of the friend→follower links goes to US while just 25% keeps local within the country. __label__=others
Furthermore, we have seen that US is the dominant country in Twitter responsible for around half of the friends, followers and links in our dataset. __label__=dataset
This produces that the Locality trends observed when studying the whole Twitter system are highly influenced by the Locality profile of US Twitter users. __label__=dataset
.In this paper we rely on the location-tag defined by the user in its Twitter profile to geolocate the user. __label__=dataset
Specifically, we are interested (for this paper) in accurately estimating the user's country. __label__=others
In this section, we validate the location-tag as a good approximation of the user's location. __label__=others
Twitter offers to its users the Tweet Geolocation Service . __label__=dataset
This service publishes along with the tweet the GPS coordinates from where the tweet was posted. __label__=others
We have collected data from 140K users that have the Tweet Geolocation Service active, have a meaningful locationtag defined in their Tweeter profile and have posted at least 5 tweets with associated GPS coordinates. __label__=dataset
For each one of these users we have computed the median geographical distance between the location specified in its Twitter profile and the GPS coordinates provided in its tweets. __label__=dataset
Figure 6presents the CDF of the computed distance across the analyzed users. __label__=method
We can observe that most of the users (&gt; 70%) typically post their tweets in a range of less than 100km from its specified location. __label__=result
Thus, we can conclude that in general the location-tag specified in the user's profile is a good estimator of the user location. __label__=result
Furthermore, we can consider it even more precise if we care about a correct mapping of the user to its country as we do in this paper. __label__=others
Figure 6: Median distance between the user's location-tag and the user's tweets GPS coordi- nates __label__=result
In this paper we perform the first comprehensive study of the Locality effect of Twitter __label__=objective
Our results demonstrate that language and cultural characteristics determine the level of Locality expected for different countries __label__=objective
Those countries with a different language than English such as Brazil typically show a high intra-country Locality
whereas those others where English is official or co-official language suffer from an external Locality effect __label__=objective
